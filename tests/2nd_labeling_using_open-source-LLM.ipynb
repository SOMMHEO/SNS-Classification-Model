{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388734e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ehddl\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\sns-categorizer-wO1G7-CE-py3.11\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict\n",
    "import torch\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import ollama\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37c98732",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/ehddl/Desktop/업무/code/sns-categorizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c8b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# load_dotenv('config/.env')\n",
    "\n",
    "# token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "# model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, token=token)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     token=token,\n",
    "#     device_map=\"auto\",  # 자동 GPU/CPU 분배\n",
    "#     load_in_4bit=True,  # 8GB 환경 필수\n",
    "#     torch_dtype=torch.float16\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8036ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 39823 entries, 0 to 39822\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   acnt_sub_nm_cleaned  35282 non-null  object\n",
      " 1   intro_txt_cleaned    36009 non-null  object\n",
      " 2   text                 39823 non-null  object\n",
      " 3   single_label         39823 non-null  object\n",
      " 4   label_id             39823 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "new = pd.read_csv(\"./tests/data/final_fine-tuning_multi-columns_data.csv\", index_col=0)\n",
    "new = new.drop(['label_list'], axis=1)\n",
    "new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f86e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 39823/39823 [00:08<00:00, 4514.16 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# --- 하이퍼파라미터 및 BERT 모델 설정 ---\n",
    "# 학습된 BERT 모델 설정\n",
    "MODEL_NAME = \"kykim/bert-kor-base\" # 또는 finetune-bert-kykim 등 님이 학습시킨 모델 경로\n",
    "FINETUNED_BERT_MODEL_PATH = \"muli-columns-kykim-bert-kor\" # finetune-bert-kykim 혹은 앙상블 모델 등\n",
    "\n",
    "# 카테고리 라벨 목록 (BERT 학습 시 사용했던 라벨과 동일해야 함)\n",
    "category_labels = ['IT', '게임', '결혼/연애', '교육', '다이어트/건강보조식품', '만화/애니/툰', '문구/완구', '미술/디자인', '반려동물', '베이비/키즈', '뷰티', '브랜드공식계정',\n",
    "                   '사진/영상', '셀럽', '스포츠', '시사', '엔터테인먼트', '여행/관광', '유명장소/핫플', '일상', '자동차/모빌리티', '짤/밈', '취미', '패션', '푸드', '홈/리빙']\n",
    "\n",
    "# --- 1. BERT 모델 및 토크나이저 로드 ---\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    FINETUNED_BERT_MODEL_PATH,\n",
    "    num_labels=len(category_labels)\n",
    ")\n",
    "bert_model.eval() # 추론 모드로 전환\n",
    "\n",
    "def tokenize_three_columns(examples):\n",
    "    combined_texts = [\n",
    "        f\"{acnt} {bert_tokenizer.sep_token} {intro} {bert_tokenizer.sep_token} {txt}\"\n",
    "        for acnt, intro, txt in zip(\n",
    "            examples[\"acnt_sub_nm_cleaned\"],\n",
    "            examples[\"intro_txt_cleaned\"],\n",
    "            examples[\"text\"]\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return bert_tokenizer(\n",
    "        combined_texts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512 \n",
    "    )\n",
    "\n",
    "predict_dataset = Dataset.from_pandas(new)\n",
    "predict_dataset = predict_dataset.map(tokenize_three_columns, batched=True)\n",
    "columns_to_remove = ['acnt_sub_nm_cleaned', 'intro_txt_cleaned', 'text']\n",
    "predict_dataset = predict_dataset.remove_columns(columns_to_remove)\n",
    "predict_dataset.set_format(type=\"torch\", columns=['input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d873837",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5392d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 예측용 TrainingArguments 및 Trainer 설정\n",
    "prediction_args = TrainingArguments(\n",
    "    output_dir=\"./prediction_output\",\n",
    "    per_device_eval_batch_size=16,\n",
    "    do_train=False,\n",
    "    do_predict=True,\n",
    "    report_to=\"none\",\n",
    "    disable_tqdm=False,\n",
    ")\n",
    "trainer = Trainer(model=bert_model, args=prediction_args)\n",
    "\n",
    "# 예측 수행\n",
    "predictions_output = trainer.predict(predict_dataset)\n",
    "logits = predictions_output.predictions\n",
    "probabilities = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "predicted_class_indices = np.argmax(logits, axis=-1)\n",
    "\n",
    "# 4. 결과 DataFrame에 추가\n",
    "predict_df['bert_probabilities'] = [probs.tolist() for probs in probabilities]\n",
    "predict_df['bert_top_label_idx'] = np.argmax(probabilities, axis=-1)\n",
    "predict_df['bert_top_label'] = [category_labels[idx] for idx in predict_df['bert_top_label_idx']]\n",
    "predict_df['bert_top_prob'] = np.max(probabilities, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f1702eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9157522035004897\n"
     ]
    }
   ],
   "source": [
    "bert_accuracy = accuracy_score(predict_df['label_id'], predict_df['bert_top_label_idx'])\n",
    "print(bert_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3e977a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LLM 설정 (2차 정제기/추론기) ---\n",
    "# LLM 설정\n",
    "LLM_MODEL_NAME = \"komt-mistral\" # Ollama에 다운로드된 모델 이름 (mistral:7b)\n",
    "LLM_CONFIDENCE_THRESHOLD = 0.8 # BERT 예측 확률이 0.8 미만일 경우에만 LLM 호출\n",
    "TOP_K_PREDICTIONS = 5 # LLM에게 전달할 BERT의 상위 예측 후보 수\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=LLM_MODEL_NAME,\n",
    "    format='json', # JSON 형식으로 응답받도록 지시 (프롬프트에서도 명시해야 함)\n",
    "    temperature=0 # 창의성 없이 일관된 답변을 받도록 온도 0으로 설정\n",
    ")\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    당신은 텍스트 분류 전문가입니다. \n",
    "    한국어로 사전학습된 BERT 모델로 SNS의 세 가지 정보를 보고(SNS 프로필 별명, SNS 프로필 설명, 미디어 게시물 텍스트), 가장 적절한 하나의 카테고리로 1차 분류를 진행했습니다. \n",
    "    하지만, 세 가지 정보를 보고 한 번 더 가장 적절한 하나의 카테고리로 분류하세요.\n",
    "    - 카테고리 목록: {category_labels}\n",
    "    - SNS 프로필 별명 : {profile_sub_name}\n",
    "    - SNS 프로필 설명 : {profile_description}\n",
    "    - 미디어 게시물 텍스트: \"{media_text}\"\n",
    "    - BERT 1차 예측 결과: {bert_predictions_info}\n",
    "    \n",
    "    최종 카테고리는 카테고리 목록에 있는 이름 중 하나여야 하며, 다른 말 없이 카테고리 이름만 JSON 형식으로 출력하세요.\n",
    "    예시: {{\"category\": \"음식\"}}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18c7193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch_with_hybrid(predict_df, category_labels):\n",
    "    \"\"\"\n",
    "    BERT 예측 결과를 담은 DataFrame을 받아 LLM으로 정제하는 함수.\n",
    "    \"\"\"\n",
    "    predict_df['final_category'] = predict_df['bert_top_label'] # 초기값은 BERT의 예측으로 설정\n",
    "    \n",
    "    for index, row in predict_df.iterrows():\n",
    "        profile_sub_name = row['acnt_sub_nm_cleaned']\n",
    "        profile_description = row['intro_txt_cleaned']\n",
    "        media_text = row['text'] \n",
    "        max_prob = row['bert_top_prob']\n",
    "        bert_top_label = row['bert_top_label']\n",
    "        probs = np.array(row['bert_probabilities'])\n",
    "\n",
    "        # LLM 호출 조건: BERT 예측이 불확실한 경우\n",
    "        if max_prob < LLM_CONFIDENCE_THRESHOLD:\n",
    "            print(f\"\\n--- 텍스트 {index+1} 처리 중 ---\")\n",
    "            print(f\"[BERT 불확실] 최고 확률 {max_prob:.4f} < {LLM_CONFIDENCE_THRESHOLD}. LLM 호출...\")\n",
    "\n",
    "            # 상위 K개 예측 후보 추출\n",
    "            top_indices = np.argsort(probs)[-TOP_K_PREDICTIONS:][::-1]\n",
    "            top_probs = probs[top_indices]\n",
    "            bert_predictions_info = []\n",
    "            for idx, prob in zip(top_indices, top_probs):\n",
    "                label = category_labels[idx]\n",
    "                bert_predictions_info.append(f\"{label} ({prob:.4f})\")\n",
    "            \n",
    "            # LangChain으로 LLM에 요청\n",
    "            prompt_variables = {\n",
    "                \"profile_sub_name\" : profile_sub_name,\n",
    "                \"profile_description\" : profile_description,\n",
    "                \"media_text\": media_text,\n",
    "                \"category_labels\": ', '.join(category_labels),\n",
    "                # \"bert_top_label\" : bert_top_label\n",
    "                \"bert_predictions_info\": ', '.join(bert_predictions_info)\n",
    "            }\n",
    "            chain = prompt_template | llm\n",
    "            \n",
    "            try:\n",
    "                llm_response = chain.invoke(prompt_variables)\n",
    "                llm_output_dict = eval(llm_response.content)\n",
    "                final_category = llm_output_dict.get('category')\n",
    "                predict_df.loc[index, 'final_category'] = final_category\n",
    "                print(f\"-> LLM 최종 결정: {final_category}\")\n",
    "            except Exception as e:\n",
    "                print(f\"LLM 호출 실패 또는 응답 파싱 오류: {e}\")\n",
    "                print(f\"-> BERT의 예측값({bert_top_label})으로 대체합니다.\")\n",
    "                predict_df.loc[index, 'final_category'] = bert_top_label\n",
    "        else:\n",
    "            print(f\"\\n--- 텍스트 {index+1} 처리 중 ---\")\n",
    "            print(f\"[BERT 확실] 최고 확률 {max_prob:.4f} >= {LLM_CONFIDENCE_THRESHOLD}. LLM 스킵.\")\n",
    "            print(f\"-> BERT 최종 결정: {bert_top_label}\")\n",
    "\n",
    "    return predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1868cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df = process_batch_with_hybrid(predict_df, category_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07c28cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 39823 entries, 0 to 39822\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   acnt_sub_nm_cleaned  35282 non-null  object \n",
      " 1   intro_txt_cleaned    36009 non-null  object \n",
      " 2   text                 39823 non-null  object \n",
      " 3   single_label         39823 non-null  object \n",
      " 4   label_id             39823 non-null  int64  \n",
      " 5   bert_probabilities   39823 non-null  object \n",
      " 6   bert_top_label_idx   39823 non-null  int64  \n",
      " 7   bert_top_label       39823 non-null  object \n",
      " 8   bert_top_prob        39823 non-null  float32\n",
      " 9   final_category       39823 non-null  object \n",
      "dtypes: float32(1), int64(2), object(7)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "predict_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dbedb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    'IT': 0,\n",
    "    '게임': 1,\n",
    "    '결혼/연애': 2,\n",
    "    '교육': 3,\n",
    "    '다이어트/건강보조식품': 4,\n",
    "    '만화/애니/툰': 5,\n",
    "    '문구/완구': 6,\n",
    "    '미술/디자인': 7,\n",
    "    '반려동물': 8,\n",
    "    '베이비/키즈': 9,\n",
    "    '뷰티': 10,\n",
    "    '브랜드공식계정': 11,\n",
    "    '사진/여행': 12, # 원래는 사진/영상\n",
    "    '셀럽': 13,\n",
    "    '스포츠': 14,\n",
    "    '시사': 15,\n",
    "    '엔터테인먼트': 16,\n",
    "    '여행/관광': 17,\n",
    "    '유명장소/핫플': 18,\n",
    "    '일상': 19,\n",
    "    '자동차/모빌리티': 20,\n",
    "    '짤/밈': 21,\n",
    "    '취미': 22,\n",
    "    '패션': 23,\n",
    "    '푸드': 24,\n",
    "    '홈/리빙': 25\n",
    "}\n",
    "\n",
    "predict_df['final_category_idx'] = predict_df['final_category'].map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "177cfdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acnt_sub_nm_cleaned</th>\n",
       "      <th>intro_txt_cleaned</th>\n",
       "      <th>text</th>\n",
       "      <th>single_label</th>\n",
       "      <th>label_id</th>\n",
       "      <th>bert_probabilities</th>\n",
       "      <th>bert_top_label_idx</th>\n",
       "      <th>bert_top_label</th>\n",
       "      <th>bert_top_prob</th>\n",
       "      <th>final_category</th>\n",
       "      <th>final_category_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>카페플렉스 카페 좋아하는 사람들</td>\n",
       "      <td>카페 좋아하는 사람들 카페플렉스 100 솔직 카페 후기만 모았어요</td>\n",
       "      <td>경기도 남양주 카페 추천 5곳 1 후탄 탁 트인 호수 뷰와 넓은 공간의 대형 남양주...</td>\n",
       "      <td>유명장소/핫플</td>\n",
       "      <td>18</td>\n",
       "      <td>[0.0010013377759605646, 0.0009921519085764885,...</td>\n",
       "      <td>18</td>\n",
       "      <td>유명장소/핫플</td>\n",
       "      <td>0.445770</td>\n",
       "      <td>카페</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>34</td>\n",
       "      <td>눈이 커졌다가 작아졌다가 지 멋대로인 무쌍세상</td>\n",
       "      <td>미러 샷</td>\n",
       "      <td>일상</td>\n",
       "      <td>19</td>\n",
       "      <td>[0.009855477139353752, 0.004870981443673372, 0...</td>\n",
       "      <td>12</td>\n",
       "      <td>사진/여행</td>\n",
       "      <td>0.443024</td>\n",
       "      <td>사진/여행</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>34</td>\n",
       "      <td>눈이 커졌다가 작아졌다가 지 멋대로인 무쌍세상</td>\n",
       "      <td>그동안 찍은 거 대방출</td>\n",
       "      <td>사진/영상</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.008311837911605835, 0.0022127674892544746, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>사진/여행</td>\n",
       "      <td>0.892561</td>\n",
       "      <td>사진/여행</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>홍채연채채</td>\n",
       "      <td>merchandiser mbtiestp</td>\n",
       "      <td>사진은 흔들려야 제맛</td>\n",
       "      <td>사진/영상</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.009718328714370728, 0.002308565191924572, 0...</td>\n",
       "      <td>12</td>\n",
       "      <td>사진/여행</td>\n",
       "      <td>0.759600</td>\n",
       "      <td>사진/여행</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>권지윤</td>\n",
       "      <td>느낌 직관적 직각적 사고의 흐름 hanyanguniv lydia kwon</td>\n",
       "      <td>곧 오픈 예정인 스튜디오에서 너무 편안하고 즐거웠던 촬영 그리고 결과물 프로필 쿨톤...</td>\n",
       "      <td>사진/영상</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.0098856370896101, 0.0025662623811513186, 0....</td>\n",
       "      <td>12</td>\n",
       "      <td>사진/여행</td>\n",
       "      <td>0.862303</td>\n",
       "      <td>사진/여행</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39280</th>\n",
       "      <td>임조은</td>\n",
       "      <td>copyright limstagram01 all rights reserved you...</td>\n",
       "      <td>나는야 토마토 공주 모델 모델 문의 스튜디오 촬영 프로필 사진 프로필 촬영 스튜디오...</td>\n",
       "      <td>사진/영상</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.007188485469669104, 0.005316786468029022, 0...</td>\n",
       "      <td>12</td>\n",
       "      <td>사진/여행</td>\n",
       "      <td>0.673414</td>\n",
       "      <td>사진/여행</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39407</th>\n",
       "      <td>조혜수</td>\n",
       "      <td>hyesu cho 020819 contact dm 접신 4화 open 매주 금 1906</td>\n",
       "      <td>웃으면 복이 와요 photo nalphoto17 hair makeup ph45</td>\n",
       "      <td>사진/영상</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.010546381585299969, 0.009681342169642448, 0...</td>\n",
       "      <td>12</td>\n",
       "      <td>사진/여행</td>\n",
       "      <td>0.700029</td>\n",
       "      <td>사진/여행</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39583</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b 컷인데 졸귀자나</td>\n",
       "      <td>짤/밈</td>\n",
       "      <td>21</td>\n",
       "      <td>[0.005355448927730322, 0.005169247277081013, 0...</td>\n",
       "      <td>12</td>\n",
       "      <td>사진/여행</td>\n",
       "      <td>0.445824</td>\n",
       "      <td>사진/여행</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39599</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>당신 사진에 감성 찰떡같이 담았어 joinmeeee0</td>\n",
       "      <td>사진/영상</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.00944224651902914, 0.002208453370258212, 0....</td>\n",
       "      <td>12</td>\n",
       "      <td>사진/여행</td>\n",
       "      <td>0.856879</td>\n",
       "      <td>사진/여행</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39651</th>\n",
       "      <td>휘원</td>\n",
       "      <td>아르듀 5기 앰버서더 ardume arduwe</td>\n",
       "      <td>쿠팡에서 산 캠코더 대만족 나름 결과물이 괜찮더래요 이것저것 모아서 유튜브이나 올려...</td>\n",
       "      <td>사진/영상</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.1643519103527069, 0.005301619414240122, 0.0...</td>\n",
       "      <td>12</td>\n",
       "      <td>사진/여행</td>\n",
       "      <td>0.721460</td>\n",
       "      <td>사진/여행</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      acnt_sub_nm_cleaned                                  intro_txt_cleaned  \\\n",
       "63      카페플렉스 카페 좋아하는 사람들               카페 좋아하는 사람들 카페플렉스 100 솔직 카페 후기만 모았어요   \n",
       "157                    34                          눈이 커졌다가 작아졌다가 지 멋대로인 무쌍세상   \n",
       "160                    34                          눈이 커졌다가 작아졌다가 지 멋대로인 무쌍세상   \n",
       "295                 홍채연채채                              merchandiser mbtiestp   \n",
       "328                   권지윤           느낌 직관적 직각적 사고의 흐름 hanyanguniv lydia kwon   \n",
       "...                   ...                                                ...   \n",
       "39280                 임조은  copyright limstagram01 all rights reserved you...   \n",
       "39407                 조혜수   hyesu cho 020819 contact dm 접신 4화 open 매주 금 1906   \n",
       "39583                 NaN                                                NaN   \n",
       "39599                 NaN                                                NaN   \n",
       "39651                  휘원                          아르듀 5기 앰버서더 ardume arduwe   \n",
       "\n",
       "                                                    text single_label  \\\n",
       "63     경기도 남양주 카페 추천 5곳 1 후탄 탁 트인 호수 뷰와 넓은 공간의 대형 남양주...      유명장소/핫플   \n",
       "157                                                 미러 샷           일상   \n",
       "160                                         그동안 찍은 거 대방출        사진/영상   \n",
       "295                                          사진은 흔들려야 제맛        사진/영상   \n",
       "328    곧 오픈 예정인 스튜디오에서 너무 편안하고 즐거웠던 촬영 그리고 결과물 프로필 쿨톤...        사진/영상   \n",
       "...                                                  ...          ...   \n",
       "39280  나는야 토마토 공주 모델 모델 문의 스튜디오 촬영 프로필 사진 프로필 촬영 스튜디오...        사진/영상   \n",
       "39407        웃으면 복이 와요 photo nalphoto17 hair makeup ph45        사진/영상   \n",
       "39583                                         b 컷인데 졸귀자나          짤/밈   \n",
       "39599                      당신 사진에 감성 찰떡같이 담았어 joinmeeee0        사진/영상   \n",
       "39651  쿠팡에서 산 캠코더 대만족 나름 결과물이 괜찮더래요 이것저것 모아서 유튜브이나 올려...        사진/영상   \n",
       "\n",
       "       label_id                                 bert_probabilities  \\\n",
       "63           18  [0.0010013377759605646, 0.0009921519085764885,...   \n",
       "157          19  [0.009855477139353752, 0.004870981443673372, 0...   \n",
       "160          12  [0.008311837911605835, 0.0022127674892544746, ...   \n",
       "295          12  [0.009718328714370728, 0.002308565191924572, 0...   \n",
       "328          12  [0.0098856370896101, 0.0025662623811513186, 0....   \n",
       "...         ...                                                ...   \n",
       "39280        12  [0.007188485469669104, 0.005316786468029022, 0...   \n",
       "39407        12  [0.010546381585299969, 0.009681342169642448, 0...   \n",
       "39583        21  [0.005355448927730322, 0.005169247277081013, 0...   \n",
       "39599        12  [0.00944224651902914, 0.002208453370258212, 0....   \n",
       "39651        12  [0.1643519103527069, 0.005301619414240122, 0.0...   \n",
       "\n",
       "       bert_top_label_idx bert_top_label  bert_top_prob final_category  \\\n",
       "63                     18        유명장소/핫플       0.445770             카페   \n",
       "157                    12          사진/여행       0.443024          사진/여행   \n",
       "160                    12          사진/여행       0.892561          사진/여행   \n",
       "295                    12          사진/여행       0.759600          사진/여행   \n",
       "328                    12          사진/여행       0.862303          사진/여행   \n",
       "...                   ...            ...            ...            ...   \n",
       "39280                  12          사진/여행       0.673414          사진/여행   \n",
       "39407                  12          사진/여행       0.700029          사진/여행   \n",
       "39583                  12          사진/여행       0.445824          사진/여행   \n",
       "39599                  12          사진/여행       0.856879          사진/여행   \n",
       "39651                  12          사진/여행       0.721460          사진/여행   \n",
       "\n",
       "       final_category_idx  \n",
       "63                    NaN  \n",
       "157                   NaN  \n",
       "160                   NaN  \n",
       "295                   NaN  \n",
       "328                   NaN  \n",
       "...                   ...  \n",
       "39280                 NaN  \n",
       "39407                 NaN  \n",
       "39583                 NaN  \n",
       "39599                 NaN  \n",
       "39651                 NaN  \n",
       "\n",
       "[238 rows x 11 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df[predict_df['final_category_idx'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b592b390",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_accuracy = accuracy_score(predict_df['label_id'], predict_df['final_category_idx'])\n",
    "print(llm_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029c28b4",
   "metadata": {},
   "source": [
    "##### Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d96a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_parquet(\"media_data_sample.parquet\")\n",
    "new_data_profile = pd.read_parquet(\"C:/Users/ehddl/Downloads/merged_data.parquet\")\n",
    "\n",
    "new_data = new_data[['acnt_id', 'media_cn']]\n",
    "new_data_profile = new_data_profile[['acnt_id', 'acnt_sub_nm', 'intro_txt']]\n",
    "\n",
    "new_data_profile.dropna(inplace=True)\n",
    "new_data.dropna(inplace=True)\n",
    "\n",
    "new = pd.merge(new_data_profile, new_data, on='acnt_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48af378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카테고리 라벨 목록 \n",
    "category_labels = ['IT', '게임', '결혼/연애', '교육', '다이어트/건강보조식품', '만화/애니/툰', '문구/완구', '미술/디자인', '반려동물', '베이비/키즈', '뷰티', '브랜드공식계정',\n",
    "                    '사진/영상', '셀럽', '스포츠', '시사', '엔터테인먼트', '여행/관광', '유명장소/핫플', '일상', '자동차/모빌리티', '짤/밈', '취미', '패션', '푸드', '홈/리빙']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d386ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LLM 설정 (2차 정제기/추론기) ---\n",
    "\n",
    "LLM_MODEL_NAME = \"komt-mistral\" # Ollama에 다운로드된 모델 이름 (ollama create komt-mistral -f ./Modelfile) -> 이렇게 생성했음\n",
    "LLM_CONFIDENCE_THRESHOLD = 0.8 # BERT 예측 확률이 0.8 미만일 경우에만 LLM 호출\n",
    "TOP_K_PREDICTIONS = 5 # LLM에게 전달할 BERT의 상위 예측 후보 수\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=LLM_MODEL_NAME,\n",
    "    format='json', # JSON 형식으로 응답받도록 지시 (프롬프트에서도 명시해야 함)\n",
    "    temperature=0 \n",
    ")\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    당신은 텍스트 분류 전문가입니다. \n",
    "    한국어로 사전학습된 BERT 모델로 SNS의 세 가지 정보를 보고(SNS 프로필 별명, SNS 프로필 설명, 미디어 게시물 텍스트), 가장 적절한 하나의 카테고리로 1차 분류를 진행했습니다. \n",
    "    하지만, 세 가지 정보를 보고 한 번 더 가장 적절한 하나의 카테고리로 분류하세요.\n",
    "    - 카테고리 목록: {category_labels}\n",
    "    - SNS 프로필 별명 : {profile_sub_name}\n",
    "    - SNS 프로필 설명 : {profile_description}\n",
    "    - 미디어 게시물 텍스트: \"{media_text}\"\n",
    "    - BERT 1차 예측 결과: {bert_predictions_info}\n",
    "    \n",
    "    최종 카테고리는 카테고리 목록에 있는 이름 중 하나여야 하며, 다른 말 없이 카테고리 이름만 JSON 형식으로 출력하세요.\n",
    "    예시: {{\"category\": \"음식\"}}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 데이터 전처리 및 BERT model 학습 ---\n",
    "def tokenize_and_predict_batch(new_profile_data, new_media_data, category_labels):\n",
    "    new_profile_data = new_profile_data[['acnt_id', 'acnt_sub_nm', 'intro_txt']]\n",
    "    new_media_data = new_media_data[['acnt_id', 'media_cn']]\n",
    "\n",
    "    new_profile_data.dropna(inplace=True)\n",
    "    new_media_data.dropna(inplace=True)\n",
    "\n",
    "    new = pd.merge(new_profile_data, new_media_data, on='acnt_id')\n",
    "\n",
    "    def clean_text(text):\n",
    "        if not isinstance(text, str):\n",
    "            return ''\n",
    "        \n",
    "        text = emoji.replace_emoji(text, replace='')\n",
    "        text = re.sub(r'[^가-힣a-zA-Z0-9\\s]', '', text)\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "        return text.strip()\n",
    "\n",
    "    new['acnt_sub_nm_cleaned'] = new['acnt_sub_nm'].apply(clean_text)\n",
    "    new['intro_txt_cleaned'] = new['intro_txt'].apply(clean_text)\n",
    "    new['media_cn_cleaned'] = new['media_cn'].apply(clean_text)\n",
    "    new = new[~new.apply(lambda row: row.astype(str).str.strip().eq('').any(), axis=1)]\n",
    "    new = new[['acnt_sub_nm_cleaned', 'intro_txt_cleaned', 'media_cn_cleaned']]\n",
    "    predict_df = new.copy()\n",
    "\n",
    "    # 학습된 BERT 모델 설정\n",
    "    MODEL_NAME = \"kykim/bert-kor-base\" \n",
    "    FINETUNED_BERT_MODEL_PATH = \"muli-columns-kykim-bert-kor\" \n",
    "\n",
    "    # BERT 모델 및 토크나이저 로드 \n",
    "    bert_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    bert_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        FINETUNED_BERT_MODEL_PATH,\n",
    "        num_labels=len(category_labels)\n",
    "    )\n",
    "    bert_model.eval() # 추론 모드로 전환\n",
    "\n",
    "    def tokenize_three_columns(examples):\n",
    "        combined_texts = [\n",
    "            f\"{acnt} {bert_tokenizer.sep_token} {intro} {bert_tokenizer.sep_token} {txt}\"\n",
    "            for acnt, intro, txt in zip(\n",
    "                examples[\"acnt_sub_nm_cleaned\"],\n",
    "                examples[\"intro_txt_cleaned\"],\n",
    "                examples[\"media_cn_cleaned\"]\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        return bert_tokenizer(\n",
    "            combined_texts,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=512 \n",
    "        )\n",
    "\n",
    "    predict_dataset = Dataset.from_pandas(new)\n",
    "    predict_dataset = predict_dataset.map(tokenize_three_columns, batched=True)\n",
    "    columns_to_remove = ['acnt_sub_nm_cleaned', 'intro_txt_cleaned', 'media_cn_cleaned']\n",
    "    predict_dataset = predict_dataset.remove_columns(columns_to_remove)\n",
    "    predict_dataset.set_format(type=\"torch\", columns=['input_ids', 'attention_mask']) # 모델에 따라서 해당 부분 변경\n",
    "    \n",
    "    # 예측용 TrainingArguments 및 Trainer 설정\n",
    "    prediction_args = TrainingArguments(\n",
    "        output_dir=\"./prediction_output\",\n",
    "        per_device_eval_batch_size=16,\n",
    "        do_train=False,\n",
    "        do_predict=True,\n",
    "        report_to=\"none\",\n",
    "        disable_tqdm=False,\n",
    "    )\n",
    "    trainer = Trainer(model=bert_model, args=prediction_args)\n",
    "\n",
    "    # 예측 수행\n",
    "    predictions_output = trainer.predict(predict_dataset)\n",
    "    logits = predictions_output.predictions\n",
    "    probabilities = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "    predicted_class_indices = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # 4. 결과 DataFrame에 추가\n",
    "    predict_df['bert_probabilities'] = [probs.tolist() for probs in probabilities]\n",
    "    predict_df['bert_top_label_idx'] = np.argmax(probabilities, axis=-1)\n",
    "    predict_df['bert_top_label'] = [category_labels[idx] for idx in predict_df['bert_top_label_idx']]\n",
    "    predict_df['bert_top_prob'] = np.max(probabilities, axis=-1)\n",
    "    \n",
    "    return predict_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32c1920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 하이브리드 라벨링 파이프라인 ---\n",
    "\n",
    "def process_batch_with_hybrid(predict_df, category_labels):\n",
    "    \"\"\"\n",
    "    BERT 예측 결과를 담은 DataFrame을 받아 LLM으로 정제하는 함수.\n",
    "    \"\"\"\n",
    "    predict_df['final_category'] = predict_df['bert_top_label'] # 초기값은 BERT의 예측으로 설정\n",
    "    \n",
    "    for index, row in predict_df.iterrows():\n",
    "        profile_sub_name = row['acnt_sub_nm_cleaned']\n",
    "        profile_description = row['intro_txt_cleaned']\n",
    "        media_text = row['media_cn_cleaned']\n",
    "        max_prob = row['bert_top_prob']\n",
    "        bert_top_label = row['bert_top_label']\n",
    "        probs = np.array(row['bert_probabilities'])\n",
    "\n",
    "        # LLM 호출 조건: BERT 예측이 불확실한 경우\n",
    "        if max_prob < LLM_CONFIDENCE_THRESHOLD:\n",
    "            print(f\"\\n--- 텍스트 {index+1} 처리 중 ---\")\n",
    "            print(f\"[BERT 불확실] 최고 확률 {max_prob:.4f} < {LLM_CONFIDENCE_THRESHOLD}. LLM 호출...\")\n",
    "\n",
    "            # 상위 K개 예측 후보 추출\n",
    "            top_indices = np.argsort(probs)[-TOP_K_PREDICTIONS:][::-1]\n",
    "            top_probs = probs[top_indices]\n",
    "            bert_predictions_info = []\n",
    "            for idx, prob in zip(top_indices, top_probs):\n",
    "                label = category_labels[idx]\n",
    "                bert_predictions_info.append(f\"{label} ({prob:.4f})\")\n",
    "            \n",
    "            # LangChain으로 LLM에 요청\n",
    "            prompt_variables = {\n",
    "                \"profile_sub_name\" : profile_sub_name,\n",
    "                \"profile_description\" : profile_description,\n",
    "                \"media_text\": media_text,\n",
    "                \"category_labels\": ', '.join(category_labels),\n",
    "                # \"bert_top_label\" : bert_top_label\n",
    "                \"bert_predictions_info\": ', '.join(bert_predictions_info)\n",
    "            }\n",
    "            chain = prompt_template | llm\n",
    "            \n",
    "            try:\n",
    "                llm_response = chain.invoke(prompt_variables)\n",
    "                llm_output_dict = eval(llm_response.content)\n",
    "                final_category = llm_output_dict.get('category')\n",
    "                predict_df.loc[index, 'final_category'] = final_category\n",
    "                print(f\"-> LLM 최종 결정: {final_category}\")\n",
    "            except Exception as e:\n",
    "                print(f\"LLM 호출 실패 또는 응답 파싱 오류: {e}\")\n",
    "                print(f\"-> BERT의 예측값({bert_top_label})으로 대체합니다.\")\n",
    "                predict_df.loc[index, 'final_category'] = bert_top_label\n",
    "        else:\n",
    "            print(f\"\\n--- 텍스트 {index+1} 처리 중 ---\")\n",
    "            print(f\"[BERT 확실] 최고 확률 {max_prob:.4f} >= {LLM_CONFIDENCE_THRESHOLD}. LLM 스킵.\")\n",
    "            print(f\"-> BERT 최종 결정: {bert_top_label}\")\n",
    "\n",
    "    return predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10766ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 14370/14370 [00:02<00:00, 5218.70 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_predictions_df = tokenize_and_predict_batch(new_data_profile, new_data, category_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a02a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_df = process_batch_with_hybrid(bert_predictions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde16e5c",
   "metadata": {},
   "source": [
    "##### simple prompt test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12df8f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "구조화된, 여러 단계의 파이프라인이 필요할 때 랭체인 사용. 주요 목적은 프롬프트 템프릿, llm, 출력 파서 등 여러 구성 요소를 연결하는 것. 단순한 단발성 프롬프트 보다 더 복잡한 작업에 활용\n",
    "프로젝트가 커질수록 일반적으로 순수 requests 코드보다 가독성이 좋고 관리가 쉬움\n",
    "'''\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model='mistral:7b',\n",
    "    format='json',\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a89841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"new_multi-columns.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efd3729b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acnt_sub_nm_cleaned</th>\n",
       "      <th>intro_txt_cleaned</th>\n",
       "      <th>media_cn_cleaned</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>prob_2</th>\n",
       "      <th>prob_3</th>\n",
       "      <th>prob_4</th>\n",
       "      <th>prob_5</th>\n",
       "      <th>...</th>\n",
       "      <th>prob_17</th>\n",
       "      <th>prob_18</th>\n",
       "      <th>prob_19</th>\n",
       "      <th>prob_20</th>\n",
       "      <th>prob_21</th>\n",
       "      <th>prob_22</th>\n",
       "      <th>prob_23</th>\n",
       "      <th>prob_24</th>\n",
       "      <th>prob_25</th>\n",
       "      <th>single_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yjmgoslow</td>\n",
       "      <td>yjm</td>\n",
       "      <td>yjm will drop a new album in the hottest summer</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.007358</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.010550</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015325</td>\n",
       "      <td>0.008815</td>\n",
       "      <td>0.170553</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>0.011930</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>엔터테인먼트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yjmgoslow</td>\n",
       "      <td>yjm</td>\n",
       "      <td>yg</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.983935</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.006725</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>일상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yjmgoslow</td>\n",
       "      <td>yjm</td>\n",
       "      <td>저의 근황은더보기</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.989646</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>일상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yjmgoslow</td>\n",
       "      <td>yjm</td>\n",
       "      <td>99년식 김윤호 생일 축하해 주셔서 다들 감사해요</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.722453</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>0.016437</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>일상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yjmgoslow</td>\n",
       "      <td>yjm</td>\n",
       "      <td>yoooooooo</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.983531</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.006814</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>일상</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  acnt_sub_nm_cleaned intro_txt_cleaned  \\\n",
       "0           yjmgoslow               yjm   \n",
       "1           yjmgoslow               yjm   \n",
       "2           yjmgoslow               yjm   \n",
       "3           yjmgoslow               yjm   \n",
       "4           yjmgoslow               yjm   \n",
       "\n",
       "                                  media_cn_cleaned  predicted_label    prob_0  \\\n",
       "0  yjm will drop a new album in the hottest summer               16  0.002786   \n",
       "1                                               yg               19  0.000232   \n",
       "2                                        저의 근황은더보기               19  0.000172   \n",
       "3                      99년식 김윤호 생일 축하해 주셔서 다들 감사해요               19  0.000497   \n",
       "4                                        yoooooooo               19  0.000247   \n",
       "\n",
       "     prob_1    prob_2    prob_3    prob_4    prob_5  ...   prob_17   prob_18  \\\n",
       "0  0.007358  0.003483  0.010550  0.001860  0.012073  ...  0.015325  0.008815   \n",
       "1  0.000165  0.000288  0.000441  0.000506  0.000460  ...  0.000781  0.000318   \n",
       "2  0.000131  0.000203  0.000350  0.000259  0.000548  ...  0.000723  0.000207   \n",
       "3  0.000658  0.010724  0.000958  0.002319  0.001174  ...  0.001867  0.003472   \n",
       "4  0.000170  0.000279  0.000497  0.000495  0.000475  ...  0.000853  0.000315   \n",
       "\n",
       "    prob_19   prob_20   prob_21   prob_22   prob_23   prob_24   prob_25  \\\n",
       "0  0.170553  0.002231  0.011930  0.003620  0.006244  0.005798  0.001646   \n",
       "1  0.983935  0.000239  0.006725  0.000145  0.000470  0.000469  0.000190   \n",
       "2  0.989646  0.000156  0.003760  0.000099  0.000315  0.000317  0.000164   \n",
       "3  0.722453  0.001677  0.003726  0.000671  0.002762  0.016437  0.003005   \n",
       "4  0.983531  0.000241  0.006814  0.000154  0.000521  0.000463  0.000194   \n",
       "\n",
       "   single_label  \n",
       "0        엔터테인먼트  \n",
       "1            일상  \n",
       "2            일상  \n",
       "3            일상  \n",
       "4            일상  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81607e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM의 최종 의견:  Based on the provided data, it seems like all the posts are about '일상' (Daily Life). However, since there could be some variation in topics within daily life such as work, personal matters, hobbies, etc., a more specific model trained for each subcategory might yield better results. In this case, manual review or additional context may be needed to accurately classify the posts into more specific categories like 'work' or 'hobbies'.\n"
     ]
    }
   ],
   "source": [
    "ollama_url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "def ollama_predict(prompt):\n",
    "    data = {\n",
    "        \"model\": \"mistral\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False # 스트리밍 없이 한 번에 응답 받기\n",
    "    }\n",
    "    response = requests.post(ollama_url, data=json.dumps(data))\n",
    "    response.raise_for_status()\n",
    "    return response.json()['response']\n",
    "\n",
    "# BERT가 '낮은 확신도'를 보인 데이터\n",
    "acnt_sub_nm_cleaned = data['acnt_sub_nm_cleaned']\n",
    "intro_txt_cleaned = data['intro_txt_cleaned']\n",
    "media_cn_cleaned = data['media_cn_cleaned']\n",
    "single_label_list = data['single_label'].unique()\n",
    "bert_label = data['single_label']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "당신은 텍스트 분류 전문가입니다. 다음 정보들의 텍스트를 보고 26개 카테고리 중 하나로 분류하세요.\n",
    "- 카테고리 목록: {single_label_list}\n",
    "- 프로필 별명 : {acnt_sub_nm_cleaned}\n",
    "- 프로필 설명 : {intro_txt_cleaned}\n",
    "- 게시물 텍스트: {media_cn_cleaned}\n",
    "\n",
    "BERT 모델은 이 게시물을 '{bert_label}'로 분류했습니다. 당신의 최종 의견은 무엇인가요?\n",
    "\"\"\"\n",
    "\n",
    "llm_label = ollama_predict(prompt)\n",
    "print(f\"LLM의 최종 의견: {llm_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decbee20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caeedf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sns-categorizer-wO1G7-CE-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
