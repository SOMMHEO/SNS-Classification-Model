{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "388734e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict\n",
    "import torch\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37c98732",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/ehddl/Desktop/업무/code/sns-categorizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c8b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# load_dotenv('config/.env')\n",
    "\n",
    "# token = os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "# model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, token=token)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     token=token,\n",
    "#     device_map=\"auto\",  # 자동 GPU/CPU 분배\n",
    "#     load_in_4bit=True,  # 8GB 환경 필수\n",
    "#     torch_dtype=torch.float16\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d96a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data = pd.read_parquet(\"media_data_sample.parquet\")\n",
    "# new_data_profile = pd.read_parquet(\"C:/Users/ehddl/Downloads/merged_data.parquet\")\n",
    "\n",
    "# new_data = new_data[['acnt_id', 'media_cn']]\n",
    "# new_data_profile = new_data_profile[['acnt_id', 'acnt_sub_nm', 'intro_txt']]\n",
    "\n",
    "# new_data_profile.dropna(inplace=True)\n",
    "# new_data.dropna(inplace=True)\n",
    "\n",
    "# new = pd.merge(new_data_profile, new_data, on='acnt_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12084f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text(text):\n",
    "#     if not isinstance(text, str):\n",
    "#         return ''\n",
    "    \n",
    "#     text = emoji.replace_emoji(text, replace='')\n",
    "#     text = re.sub(r'[^가-힣a-zA-Z0-9\\s]', '', text)\n",
    "#     text = text.lower()\n",
    "#     text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "#     return text.strip()\n",
    "\n",
    "# new['acnt_sub_nm_cleaned'] = new['acnt_sub_nm'].apply(clean_text)\n",
    "# new['intro_txt_cleaned'] = new['intro_txt'].apply(clean_text)\n",
    "# new['media_cn_cleaned'] = new['media_cn'].apply(clean_text)\n",
    "# new = new[~new.apply(lambda row: row.astype(str).str.strip().eq('').any(), axis=1)]\n",
    "# new = new[['acnt_sub_nm_cleaned', 'intro_txt_cleaned', 'media_cn_cleaned']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "680f86e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 14370/14370 [00:02<00:00, 4973.99 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# --- 0. 하이퍼파라미터 및 모델 설정 ---\n",
    "# 학습된 BERT 모델 설정\n",
    "MODEL_NAME = \"kykim/bert-kor-base\" # 또는 finetune-bert-kykim 등 님이 학습시킨 모델 경로\n",
    "FINETUNED_BERT_MODEL_PATH = \"muli-columns-kykim-bert-kor\" # finetune-bert-kykim 혹은 앙상블 모델 등\n",
    "\n",
    "# 카테고리 라벨 목록 (BERT 학습 시 사용했던 라벨과 동일해야 함)\n",
    "category_labels = ['IT', '게임', '결혼/연애', '교육', '다이어트/건강보조식품', '만화/애니/툰', '문구/완구', '미술/디자인', '반려동물', '베이비/키즈', '뷰티', '브랜드공식계정',\n",
    "                   '사진/여행', '셀럽', '스포츠', '시사', '엔터테인먼트', '여행/관광', '유명장소/핫플', '일상', '자동차/모빌리티', '짤/밈', '취미', '패션', '푸드', '홈/리빙'] # 27개 실제 라벨\n",
    "\n",
    "# --- 1. BERT 모델 및 토크나이저 로드 ---\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "bert_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    FINETUNED_BERT_MODEL_PATH,\n",
    "    num_labels=len(category_labels)\n",
    ")\n",
    "bert_model.eval() # 추론 모드로 전환\n",
    "\n",
    "def tokenize_three_columns(examples):\n",
    "    combined_texts = [\n",
    "        f\"{acnt} {bert_tokenizer.sep_token} {intro} {bert_tokenizer.sep_token} {txt}\"\n",
    "        for acnt, intro, txt in zip(\n",
    "            examples[\"acnt_sub_nm_cleaned\"],\n",
    "            examples[\"intro_txt_cleaned\"],\n",
    "            examples[\"media_cn_cleaned\"]\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return bert_tokenizer(\n",
    "        combined_texts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512 \n",
    "    )\n",
    "\n",
    "predict_dataset = Dataset.from_pandas(new)\n",
    "predict_dataset = predict_dataset.map(tokenize_three_columns, batched=True)\n",
    "columns_to_remove = ['acnt_sub_nm_cleaned', 'intro_txt_cleaned', 'media_cn_cleaned']\n",
    "predict_dataset = predict_dataset.remove_columns(columns_to_remove)\n",
    "predict_dataset.set_format(type=\"torch\", columns=['input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28d386ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. LLM 설정 (2차 정제기/추론기) ---\n",
    "# LLM 설정\n",
    "LLM_MODEL_NAME = \"mistral:7b\" # Ollama에 다운로드된 모델 이름\n",
    "LLM_CONFIDENCE_THRESHOLD = 0.8 # BERT 예측 확률이 0.8 미만일 경우에만 LLM 호출\n",
    "TOP_K_PREDICTIONS = 5 # LLM에게 전달할 BERT의 상위 예측 후보 수\n",
    "\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=LLM_MODEL_NAME,\n",
    "    format='json', # JSON 형식으로 응답받도록 지시 (프롬프트에서도 명시해야 함)\n",
    "    temperature=0 # 창의성 없이 일관된 답변을 받도록 온도 0으로 설정\n",
    ")\n",
    "\n",
    "# LLM에게 전달할 프롬프트 템플릿\n",
    "# {text}, {category_labels}, {bert_predictions_info} 변수를 동적으로 채워넣을 것입니다.\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    당신은 텍스트 분류 전문가입니다. 다음 SNS 텍스트를 가장 적절한 하나의 카테고리로 분류하세요.\n",
    "    - 카테고리 목록: {category_labels}\n",
    "    - 텍스트: \"{text}\"\n",
    "    - BERT 1차 예측 결과: {bert_predictions_info}\n",
    "    \n",
    "    최종 카테고리는 카테고리 목록에 있는 이름 중 하나여야 하며, 다른 말 없이 카테고리 이름만 JSON 형식으로 출력하세요.\n",
    "    예시: {{\"category\": \"음식\"}}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366ea91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 데이터 전처리 및 하이브리드 라벨링 파이프라인 ---\n",
    "def tokenize_and_predict_batch(new_profile_data, new_media_data):\n",
    "    new_profile_data = new_profile_data[['acnt_id', 'acnt_sub_nm', 'intro_txt']]\n",
    "    new_media_data = new_media_data[['acnt_id', 'media_cn']]\n",
    "\n",
    "    new_profile_data.dropna(inplace=True)\n",
    "    new_media_data.dropna(inplace=True)\n",
    "\n",
    "    new = pd.merge(new_profile_data, new_media_data, on='acnt_id')\n",
    "\n",
    "    def clean_text(text):\n",
    "        if not isinstance(text, str):\n",
    "            return ''\n",
    "        \n",
    "        text = emoji.replace_emoji(text, replace='')\n",
    "        text = re.sub(r'[^가-힣a-zA-Z0-9\\s]', '', text)\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "        return text.strip()\n",
    "\n",
    "    new['acnt_sub_nm_cleaned'] = new['acnt_sub_nm'].apply(clean_text)\n",
    "    new['intro_txt_cleaned'] = new['intro_txt'].apply(clean_text)\n",
    "    new['media_cn_cleaned'] = new['media_cn'].apply(clean_text)\n",
    "    new = new[~new.apply(lambda row: row.astype(str).str.strip().eq('').any(), axis=1)]\n",
    "    new = new[['acnt_sub_nm_cleaned', 'intro_txt_cleaned', 'media_cn_cleaned']]\n",
    "    predict_df = new.copy()\n",
    "\n",
    "    def tokenize_three_columns(examples):\n",
    "        combined_texts = [\n",
    "            f\"{acnt} {bert_tokenizer.sep_token} {intro} {bert_tokenizer.sep_token} {txt}\"\n",
    "            for acnt, intro, txt in zip(\n",
    "                examples[\"acnt_sub_nm_cleaned\"],\n",
    "                examples[\"intro_txt_cleaned\"],\n",
    "                examples[\"media_cn_cleaned\"]\n",
    "            )\n",
    "        ]\n",
    "        \n",
    "        return bert_tokenizer(\n",
    "            combined_texts,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=512 \n",
    "        )\n",
    "\n",
    "    predict_dataset = Dataset.from_pandas(new)\n",
    "    predict_dataset = predict_dataset.map(tokenize_three_columns, batched=True)\n",
    "    columns_to_remove = ['acnt_sub_nm_cleaned', 'intro_txt_cleaned', 'media_cn_cleaned']\n",
    "    predict_dataset = predict_dataset.remove_columns(columns_to_remove)\n",
    "    predict_dataset.set_format(type=\"torch\", columns=['input_ids', 'attention_mask'])\n",
    "    \n",
    "    # 예측용 TrainingArguments 및 Trainer 설정\n",
    "    prediction_args = TrainingArguments(\n",
    "        output_dir=\"./prediction_output\",\n",
    "        per_device_eval_batch_size=16,\n",
    "        do_train=False,\n",
    "        do_predict=True,\n",
    "        report_to=\"none\",\n",
    "        disable_tqdm=False,\n",
    "    )\n",
    "    trainer = Trainer(model=bert_model, args=prediction_args)\n",
    "\n",
    "    # 예측 수행\n",
    "    predictions_output = trainer.predict(predict_dataset)\n",
    "    logits = predictions_output.predictions\n",
    "    probabilities = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "    predicted_class_indices = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # 4. 결과 DataFrame에 추가\n",
    "    predict_df['bert_probabilities'] = [probs.tolist() for probs in probabilities]\n",
    "    predict_df['bert_top_label_idx'] = np.argmax(probabilities, axis=-1)\n",
    "    predict_df['bert_top_label'] = [category_labels[idx] for idx in predict_df['bert_top_label_idx']]\n",
    "    predict_df['bert_top_prob'] = np.max(probabilities, axis=-1)\n",
    "    \n",
    "    return predict_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c32c1920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch_with_hybrid(predict_df):\n",
    "    \"\"\"\n",
    "    BERT 예측 결과를 담은 DataFrame을 받아 LLM으로 정제하는 함수.\n",
    "    \"\"\"\n",
    "    predict_df['final_category'] = predict_df['bert_top_label'] # 초기값은 BERT의 예측으로 설정\n",
    "    \n",
    "    for index, row in predict_df.iterrows():\n",
    "        text = row['media_cn']\n",
    "        max_prob = row['bert_top_prob']\n",
    "        bert_top_label = row['bert_top_label']\n",
    "        probs = np.array(row['bert_probabilities'])\n",
    "\n",
    "        # LLM 호출 조건: BERT 예측이 불확실한 경우\n",
    "        if max_prob < LLM_CONFIDENCE_THRESHOLD:\n",
    "            print(f\"\\n--- 텍스트 {index+1} 처리 중 ---\")\n",
    "            print(f\"[BERT 불확실] 최고 확률 {max_prob:.4f} < {LLM_CONFIDENCE_THRESHOLD}. LLM 호출...\")\n",
    "\n",
    "            # 상위 K개 예측 후보 추출\n",
    "            top_indices = np.argsort(probs)[-TOP_K_PREDICTIONS:][::-1]\n",
    "            top_probs = probs[top_indices]\n",
    "            bert_predictions_info = []\n",
    "            for idx, prob in zip(top_indices, top_probs):\n",
    "                label = category_labels[idx]\n",
    "                bert_predictions_info.append(f\"{label} ({prob:.4f})\")\n",
    "            \n",
    "            # LangChain으로 LLM에 요청\n",
    "            prompt_variables = {\n",
    "                \"text\": text,\n",
    "                \"category_labels\": ', '.join(category_labels),\n",
    "                \"bert_predictions_info\": ', '.join(bert_predictions_info)\n",
    "            }\n",
    "            chain = prompt_template | llm\n",
    "            \n",
    "            try:\n",
    "                llm_response = chain.invoke(prompt_variables)\n",
    "                llm_output_dict = eval(llm_response.content)\n",
    "                final_category = llm_output_dict.get('category')\n",
    "                predict_df.loc[index, 'final_category'] = final_category\n",
    "                print(f\"-> LLM 최종 결정: {final_category}\")\n",
    "            except Exception as e:\n",
    "                print(f\"LLM 호출 실패 또는 응답 파싱 오류: {e}\")\n",
    "                print(f\"-> BERT의 예측값({bert_top_label})으로 대체합니다.\")\n",
    "                predict_df.loc[index, 'final_category'] = bert_top_label\n",
    "        else:\n",
    "            print(f\"\\n--- 텍스트 {index+1} 처리 중 ---\")\n",
    "            print(f\"[BERT 확실] 최고 확률 {max_prob:.4f} >= {LLM_CONFIDENCE_THRESHOLD}. LLM 스킵.\")\n",
    "            print(f\"-> BERT 최종 결정: {bert_top_label}\")\n",
    "\n",
    "    return predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10766ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 14370/14370 [00:02<00:00, 5218.70 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_predictions_df = tokenize_and_predict_batch(new_data_profile, new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83a02a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_results_df = process_batch_with_hybrid(bert_predictions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde16e5c",
   "metadata": {},
   "source": [
    "##### simple prompt test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12df8f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "구조화된, 여러 단계의 파이프라인이 필요할 때 랭체인 사용. 주요 목적은 프롬프트 템프릿, llm, 출력 파서 등 여러 구성 요소를 연결하는 것. 단순한 단발성 프롬프트 보다 더 복잡한 작업에 활용\n",
    "프로젝트가 커질수록 일반적으로 순수 requests 코드보다 가독성이 좋고 관리가 쉬움\n",
    "'''\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model='mistral:7b',\n",
    "    format='json',\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a89841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"new_multi-columns.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "efd3729b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acnt_sub_nm_cleaned</th>\n",
       "      <th>intro_txt_cleaned</th>\n",
       "      <th>media_cn_cleaned</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>prob_0</th>\n",
       "      <th>prob_1</th>\n",
       "      <th>prob_2</th>\n",
       "      <th>prob_3</th>\n",
       "      <th>prob_4</th>\n",
       "      <th>prob_5</th>\n",
       "      <th>...</th>\n",
       "      <th>prob_17</th>\n",
       "      <th>prob_18</th>\n",
       "      <th>prob_19</th>\n",
       "      <th>prob_20</th>\n",
       "      <th>prob_21</th>\n",
       "      <th>prob_22</th>\n",
       "      <th>prob_23</th>\n",
       "      <th>prob_24</th>\n",
       "      <th>prob_25</th>\n",
       "      <th>single_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yjmgoslow</td>\n",
       "      <td>yjm</td>\n",
       "      <td>yjm will drop a new album in the hottest summer</td>\n",
       "      <td>16</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.007358</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.010550</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.012073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015325</td>\n",
       "      <td>0.008815</td>\n",
       "      <td>0.170553</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>0.011930</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>0.006244</td>\n",
       "      <td>0.005798</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>엔터테인먼트</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yjmgoslow</td>\n",
       "      <td>yjm</td>\n",
       "      <td>yg</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.983935</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.006725</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>일상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yjmgoslow</td>\n",
       "      <td>yjm</td>\n",
       "      <td>저의 근황은더보기</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.989646</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.003760</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>일상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yjmgoslow</td>\n",
       "      <td>yjm</td>\n",
       "      <td>99년식 김윤호 생일 축하해 주셔서 다들 감사해요</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.001174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.722453</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.002762</td>\n",
       "      <td>0.016437</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>일상</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yjmgoslow</td>\n",
       "      <td>yjm</td>\n",
       "      <td>yoooooooo</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.983531</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.006814</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>일상</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  acnt_sub_nm_cleaned intro_txt_cleaned  \\\n",
       "0           yjmgoslow               yjm   \n",
       "1           yjmgoslow               yjm   \n",
       "2           yjmgoslow               yjm   \n",
       "3           yjmgoslow               yjm   \n",
       "4           yjmgoslow               yjm   \n",
       "\n",
       "                                  media_cn_cleaned  predicted_label    prob_0  \\\n",
       "0  yjm will drop a new album in the hottest summer               16  0.002786   \n",
       "1                                               yg               19  0.000232   \n",
       "2                                        저의 근황은더보기               19  0.000172   \n",
       "3                      99년식 김윤호 생일 축하해 주셔서 다들 감사해요               19  0.000497   \n",
       "4                                        yoooooooo               19  0.000247   \n",
       "\n",
       "     prob_1    prob_2    prob_3    prob_4    prob_5  ...   prob_17   prob_18  \\\n",
       "0  0.007358  0.003483  0.010550  0.001860  0.012073  ...  0.015325  0.008815   \n",
       "1  0.000165  0.000288  0.000441  0.000506  0.000460  ...  0.000781  0.000318   \n",
       "2  0.000131  0.000203  0.000350  0.000259  0.000548  ...  0.000723  0.000207   \n",
       "3  0.000658  0.010724  0.000958  0.002319  0.001174  ...  0.001867  0.003472   \n",
       "4  0.000170  0.000279  0.000497  0.000495  0.000475  ...  0.000853  0.000315   \n",
       "\n",
       "    prob_19   prob_20   prob_21   prob_22   prob_23   prob_24   prob_25  \\\n",
       "0  0.170553  0.002231  0.011930  0.003620  0.006244  0.005798  0.001646   \n",
       "1  0.983935  0.000239  0.006725  0.000145  0.000470  0.000469  0.000190   \n",
       "2  0.989646  0.000156  0.003760  0.000099  0.000315  0.000317  0.000164   \n",
       "3  0.722453  0.001677  0.003726  0.000671  0.002762  0.016437  0.003005   \n",
       "4  0.983531  0.000241  0.006814  0.000154  0.000521  0.000463  0.000194   \n",
       "\n",
       "   single_label  \n",
       "0        엔터테인먼트  \n",
       "1            일상  \n",
       "2            일상  \n",
       "3            일상  \n",
       "4            일상  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81607e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "def ollama_predict(prompt):\n",
    "    data = {\n",
    "        \"model\": \"mistral\",\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False # 스트리밍 없이 한 번에 응답 받기\n",
    "    }\n",
    "    response = requests.post(ollama_url, data=json.dumps(data))\n",
    "    response.raise_for_status()\n",
    "    return response.json()['response']\n",
    "\n",
    "# BERT가 '낮은 확신도'를 보인 데이터\n",
    "acnt_sub_nm_cleaned = data['acnt_sub_nm_cleaned']\n",
    "intro_txt_cleaned = data['intro_txt_cleaned']\n",
    "media_cn_cleaned = data['media_cn_cleaned']\n",
    "single_label_list = data['single_label_list'].unique()\n",
    "bert_label = data['single_label']\n",
    "\n",
    "prompt = f\"\"\"\n",
    "당신은 텍스트 분류 전문가입니다. 다음 정보들의 텍스트를 보고 26개 카테고리 중 하나로 분류하세요.\n",
    "- 카테고리 목록: {single_label_list}\n",
    "- 프로필 별명 : {acnt_sub_nm_cleaned}\n",
    "- 프로필 설명 : {intro_txt_cleaned}\n",
    "- 게시물 텍스트: {media_cn_cleaned}\n",
    "\n",
    "BERT 모델은 이 게시물을 '{bert_label}'로 분류했습니다. 당신의 최종 의견은 무엇인가요?\n",
    "\"\"\"\n",
    "\n",
    "llm_label = ollama_predict(prompt)\n",
    "print(f\"LLM의 최종 의견: {llm_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decbee20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caeedf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sns-categorizer-wO1G7-CE-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
