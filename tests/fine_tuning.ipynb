{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66c36756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ehddl\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\sns-categorizer-wO1G7-CE-py3.11\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "# from torch.utils.data import Dataset, DataLoader -> datasets 라이브러리랑 충돌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54cd86f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 3050\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count()) \n",
    "print(torch.cuda.get_device_name(0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de28eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch==2.5.1+cu121 --index-url https://download.pytorch.org/whl/cu121\n",
    "# poetry run pip install torch==2.5.1+cu121 --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# torch gpu버전을 pip install torch==2.5.1+cu121 --index-url https://download.pytorch.org/whl/cu121로 설치\n",
    "# huggingface transformer 라이브러리가 pytorch 2.6 미만 버전은 보안 이슈로 강제로 차단하는데, gpu 버전의 torch는 현재 pip로 설치가 불가능. 따라서 우회하는 user_safetensor를 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "825d6343",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/ehddl/Desktop/업무/code/sns-categorizer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "167892c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>휴가 돌려줘</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>관종들 릴스 리스타 그램 릴스 초보</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>날이 좋아서</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>행복했던 9월 고마워</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>협찬 동결건조야채 블록 1개로 13종의 보라 야채와 유산균 섭취 가능 보라색 안토시...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42919</th>\n",
       "      <td>아름다운 색채의 향연, 수채화로 그려낸 풍경화.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42920</th>\n",
       "      <td>예술가의 아침, 커피와 함께하는 스케치 시간.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42921</th>\n",
       "      <td>디자인 스튜디오에서의 하루, 창의력 넘치는 공간.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42922</th>\n",
       "      <td>도시의 밤을 담은 사진, 빛과 그림자의 조화.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42923</th>\n",
       "      <td>미니어처 아트, 작은 세계 속에 담긴 큰 이야기.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42924 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label_id\n",
       "0                                                 휴가 돌려줘        19\n",
       "1                                    관종들 릴스 리스타 그램 릴스 초보        21\n",
       "2                                                 날이 좋아서        19\n",
       "3                                            행복했던 9월 고마워        19\n",
       "4      협찬 동결건조야채 블록 1개로 13종의 보라 야채와 유산균 섭취 가능 보라색 안토시...         8\n",
       "...                                                  ...       ...\n",
       "42919                         아름다운 색채의 향연, 수채화로 그려낸 풍경화.         8\n",
       "42920                          예술가의 아침, 커피와 함께하는 스케치 시간.         8\n",
       "42921                        디자인 스튜디오에서의 하루, 창의력 넘치는 공간.         8\n",
       "42922                          도시의 밤을 담은 사진, 빛과 그림자의 조화.         8\n",
       "42923                        미니어처 아트, 작은 세계 속에 담긴 큰 이야기.         8\n",
       "\n",
       "[42924 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"tests/final_fine_tuning_augmented_data.csv\", index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d166695d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"spelled_checked_text\"] = data[\"spelled_checked_text\"].fillna(\"\")  # NaN → 빈 문자열\n",
    "# data[\"spelled_checked_text\"] = data.apply(\n",
    "#     lambda row: row[\"media_cn_cleaned\"] if row[\"spelled_checked_text\"] == \"\" else row[\"spelled_checked_text\"],\n",
    "#     axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "198dfcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop(['media_cn_cleaned'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cd22dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size= 0.2, stratify=data['label_id'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eda8a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface의 datasets.Dataset을 사용하는 방식\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train' : Dataset.from_pandas(train),\n",
    "    'test' : Dataset.from_pandas(test)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ad1c85",
   "metadata": {},
   "source": [
    "##### basic code & hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "868e111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model & toknizer loading\n",
    "\n",
    "model_name = \"BM-K/KoSimCSE-roberta\" # BM-K/KoSimCSE-roberta, kykim/bert-kor-base\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "## 모델이 bert 계열이고, 속도가 중요하면 BertTkenizerFast\n",
    "## 모델을 자주 비꾸거나 여러 모델 실험할 계획이면 AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1df0842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 34339/34339 [00:20<00:00, 1683.33 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 문장 길이 통계 (토큰 기준):\n",
      "90th 퍼센타일: 292.0\n",
      "95th 퍼센타일: 360.0\n",
      "99th 퍼센타일: 512.0\n",
      "가장 긴 문장 길이 (Truncation 적용 후): 512\n"
     ]
    }
   ],
   "source": [
    "# max_length 최적화를 위해서 ids의 길이 확인\n",
    "# 길이 계산 함수 정의\n",
    "def get_tokenized_length(example):\n",
    "    # truncation=True를 통해 max_length를 초과하는 텍스트는 잘립니다.\n",
    "    # 모델에 실제로 들어갈 길이만 측정하는 것이 중요합니다.\n",
    "    # padding은 길이를 측정하는 단계에서는 필요하지 않으므로 사용하지 않습니다.\n",
    "    tokenized_output = tokenizer(example[\"text\"], truncation=True)\n",
    "    return {\"length\": len(tokenized_output[\"input_ids\"])}\n",
    "\n",
    "# dataset['train']의 'text' 컬럼에 대해 길이 계산\n",
    "# map 함수는 새로운 컬럼('length')을 추가하여 반환합니다.\n",
    "lengths_dataset = dataset[\"train\"].map(get_tokenized_length, batched=False, remove_columns=dataset[\"train\"].column_names)\n",
    "\n",
    "# 'length' 컬럼에서 모든 길이를 numpy 배열로 추출\n",
    "text_lengths = np.array(lengths_dataset['length'])\n",
    "\n",
    "# 퍼센타일 값 계산\n",
    "percentile_90 = np.percentile(text_lengths, 90)\n",
    "percentile_95 = np.percentile(text_lengths, 95)\n",
    "percentile_99 = np.percentile(text_lengths, 99)\n",
    "max_length_observed = np.max(text_lengths)\n",
    "\n",
    "print(f\"훈련 데이터 문장 길이 통계 (토큰 기준):\")\n",
    "print(f\"90th 퍼센타일: {percentile_90}\")\n",
    "print(f\"95th 퍼센타일: {percentile_95}\")\n",
    "print(f\"99th 퍼센타일: {percentile_99}\")\n",
    "print(f\"가장 긴 문장 길이 (Truncation 적용 후): {max_length_observed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08123c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 34339/34339 [00:03<00:00, 10148.68 examples/s]\n",
      "Map: 100%|██████████| 8585/8585 [00:00<00:00, 11196.45 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_fn(ex):\n",
    "    return tokenizer(ex[\"text\"], padding=\"max_length\", truncation=True, max_length=128) # max_length 조정 (128->512)\n",
    "\n",
    "dataset = dataset.map(tokenize_fn, batched=True)\n",
    "dataset = dataset.rename_column(\"label_id\", \"label\")\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7c0d82d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 34339\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "    num_rows: 8585\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'])\n",
    "print(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f864582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at BM-K/KoSimCSE-roberta and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# setting model\n",
    "\n",
    "num_labels = data['label_id'].nunique()\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    use_safetensors=True # gpu 버전 사용 시 추가\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "43801909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting trainer\n",
    "# !pip install accelerate>=0.26.0\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"finetune-BM-K\", # finetune-BM-K\n",
    "    eval_strategy=\"epoch\", # evaluation_strategy -> eval_strategy\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5, # 3 -> 10\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.06, # 전체 학습 스템의 6% 동안 학습률을 0부터 learning_rate 까지 선형적으로 증가\n",
    "    weight_decay=0.01, # 정규화 진행\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True, # 학습 종료 시 검증 세트에서 가장 성능이 좋았던 모델 로드\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True # accuracy는 높을수록 좋으므로 True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc640b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(axis=-1)\n",
    "    labels = p.label_ids\n",
    "    return {\"accuracy\": accuracy_score(labels, preds)}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9e3a4619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10735' max='10735' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10735/10735 2:12:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.097200</td>\n",
       "      <td>1.059403</td>\n",
       "      <td>0.707863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.865400</td>\n",
       "      <td>0.971543</td>\n",
       "      <td>0.725684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.711000</td>\n",
       "      <td>1.031504</td>\n",
       "      <td>0.723588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.488200</td>\n",
       "      <td>1.082983</td>\n",
       "      <td>0.719161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.397700</td>\n",
       "      <td>1.134532</td>\n",
       "      <td>0.721840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10735, training_loss=0.8034730520368344, metrics={'train_runtime': 7938.8275, 'train_samples_per_second': 21.627, 'train_steps_per_second': 1.352, 'total_flos': 1.129614680315136e+16, 'train_loss': 0.8034730520368344, 'epoch': 5.0})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26466e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('finetune-bert-kor\\\\tokenizer_config.json',\n",
       " 'finetune-bert-kor\\\\special_tokens_map.json',\n",
       " 'finetune-bert-kor\\\\vocab.txt',\n",
       " 'finetune-bert-kor\\\\added_tokens.json',\n",
       " 'finetune-bert-kor\\\\tokenizer.json')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"finetune-bert-kor\")\n",
    "tokenizer.save_pretrained(\"finetune-bert-kor\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0827e10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('finetune-BM-K\\\\tokenizer_config.json',\n",
       " 'finetune-BM-K\\\\special_tokens_map.json',\n",
       " 'finetune-BM-K\\\\vocab.txt',\n",
       " 'finetune-BM-K\\\\added_tokens.json',\n",
       " 'finetune-BM-K\\\\tokenizer.json')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"finetune-BM-K\")\n",
    "tokenizer.save_pretrained(\"finetune-BM-K\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f9ba9b",
   "metadata": {},
   "source": [
    "##### ensemble - voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac0ae272",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = data['label_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87e50f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(42000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_1 = \"kykim/bert-kor-base\"\n",
    "model_path_1 = \"finetune-bert-kor\"\n",
    "\n",
    "model1 = AutoModelForSequenceClassification.from_pretrained(model_path_1, num_labels=num_labels)\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fc6f6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=26, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_2 = \"BM-K/KoSimCSE-roberta\"\n",
    "model_path_2 = \"finetune-BM-K\"\n",
    "\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(model_path_2, num_labels=num_labels)\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69813fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불필요한 __index_level_0__ 컬럼 제거 (DataFrame.to_dict() 시 생길 수 있음)\n",
    "if \"__index_level_0__\" in dataset[\"train\"].column_names:\n",
    "    dataset[\"train\"] = dataset[\"train\"].remove_columns([\"__index_level_0__\"])\n",
    "if \"__index_level_0__\" in dataset[\"test\"].column_names:\n",
    "    dataset[\"test\"] = dataset[\"test\"].remove_columns([\"__index_level_0__\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43b58cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 34339/34339 [00:06<00:00, 4958.51 examples/s]\n",
      "Map: 100%|██████████| 8585/8585 [00:01<00:00, 5166.10 examples/s]\n",
      "Map: 100%|██████████| 34339/34339 [00:06<00:00, 5015.78 examples/s]\n",
      "Map: 100%|██████████| 8585/8585 [00:01<00:00, 4821.62 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 1 (kykim/bert-kor-base)의 테스트 정확도: 0.7600\n",
      "모델 2 (BM-K/KoSimCSE-roberta)의 테스트 정확도: 0.7437\n",
      "앙상블 모델의 테스트 정확도 (소프트 보팅): 0.7609\n"
     ]
    }
   ],
   "source": [
    "# --- 0.4. 각 모델에 맞는 토크나이저 로드 및 텍스트 토큰화 ---\n",
    "\n",
    "# kykim 모델용 토크나이저 및 데이터셋\n",
    "tokenizer_kykim = AutoTokenizer.from_pretrained(\"kykim/bert-kor-base\")\n",
    "def tokenize_fn_kykim(examples):\n",
    "    return tokenizer_kykim(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "dataset_kykim_tokenized = dataset.map(tokenize_fn_kykim, batched=True)\n",
    "dataset_kykim_tokenized = dataset_kykim_tokenized.rename_column(\"label_id\", \"label\")\n",
    "dataset_kykim_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "# KoSimCSE 모델용 토크나이저 및 데이터셋\n",
    "# BM-K/KoSimCSE-roberta 모델은 'klue/roberta-base' 토크나이저를 기반으로 할 가능성이 높습니다.\n",
    "# 정확한 토크나이저 이름은 'BM-K/KoSimCSE-roberta' 모델 페이지에서 확인하는 것이 좋습니다.\n",
    "tokenizer_kosimcse = AutoTokenizer.from_pretrained(\"BM-K/KoSimCSE-roberta\") # <-- 해당 모델의 토크나이저!\n",
    "def tokenize_fn_kosimcse(examples):\n",
    "    # KoSimCSE 토크나이저는 token_type_ids를 생성하지 않을 수 있습니다.\n",
    "    # 하지만 RoBERTa 모델이 내부적으로 이 인자를 기대할 수 있으니\n",
    "    # 필요하다면 아래와 같이 0으로 채워넣는 로직을 추가해봅니다. (시험적)\n",
    "    tokenized_output = tokenizer_kosimcse(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "    if \"token_type_ids\" not in tokenized_output:\n",
    "        tokenized_output[\"token_type_ids\"] = [[0] * len(ids) for ids in tokenized_output[\"input_ids\"]]\n",
    "    return tokenized_output\n",
    "\n",
    "dataset_kosimcse_tokenized = dataset.map(tokenize_fn_kosimcse, batched=True)\n",
    "dataset_kosimcse_tokenized = dataset_kosimcse_tokenized.rename_column(\"label_id\", \"label\")\n",
    "# 중요한 점: kosimcse 모델이 token_type_ids를 기대한다면 set_format에도 추가\n",
    "dataset_kosimcse_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\", \"label\"])\n",
    "# 만약 token_type_ids를 넣었는데도 에러나면 다시 빼보고 테스트\n",
    "\n",
    "# --- 2. Trainer를 사용하여 각 모델의 예측 로짓(Logits) 얻기 ---\n",
    "# Trainer를 사용하면 편리하게 예측을 수행할 수 있습니다.\n",
    "# 예측을 위한 Trainer는 학습 인자가 필요 없으므로 간소화합니다.\n",
    "# eval_dataset 대신 test_dataset을 사용한다고 가정\n",
    "\n",
    "# 더미 TrainingArguments (예측용이므로 대부분의 인자는 중요하지 않음)\n",
    "prediction_args = TrainingArguments(\n",
    "    output_dir=\"./voting_prediction_output\", # 임시 출력 디렉토리\n",
    "    per_device_eval_batch_size=16, # 평가 배치 크기\n",
    "    do_train=False,\n",
    "    do_predict=True,\n",
    "    report_to=\"none\", # W&B 등 로깅 비활성화\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "# Model 1 Prediction\n",
    "trainer1 = Trainer(model=model1, args=prediction_args)\n",
    "predictions1 = trainer1.predict(dataset_kykim_tokenized[\"test\"])\n",
    "logits1 = predictions1.predictions # numpy array 형태의 로짓\n",
    "\n",
    "# Model 2 Prediction\n",
    "trainer2 = Trainer(model=model2, args=prediction_args)\n",
    "predictions2 = trainer2.predict(dataset_kosimcse_tokenized[\"test\"])\n",
    "logits2 = predictions2.predictions\n",
    "\n",
    "# --- 3. 로짓(Logits) 또는 확률(Probabilities) 평균내기 ---\n",
    "# 소프트 보팅은 로짓 또는 softmax 확률을 평균낼 수 있습니다.\n",
    "# 일반적으로 로짓을 평균내는 것이 더 안정적이라고 알려져 있습니다.\n",
    "# (softmax는 비선형 변환이므로 평균 내기 전에 로짓 상태에서 평균 내는 것이 좋습니다.)\n",
    "\n",
    "# 로짓 평균\n",
    "ensemble_logits = (logits1 + logits2) / 2 # 모델이 3개라면 (logits1 + logits2 + logits3) / 3\n",
    "\n",
    "# 평균 로짓에서 최종 예측 클래스 선택\n",
    "ensemble_predictions = np.argmax(ensemble_logits, axis=-1)\n",
    "\n",
    "# 실제 라벨 가져오기 (predictions1 객체에서 가져오는 것이 편리)\n",
    "true_labels = predictions1.label_ids\n",
    "\n",
    "# --- 4. 앙상블 성능 평가 ---\n",
    "ensemble_accuracy = accuracy_score(true_labels, ensemble_predictions)\n",
    "\n",
    "print(f\"모델 1 ({model_name_1})의 테스트 정확도: {accuracy_score(true_labels, np.argmax(logits1, axis=-1)):.4f}\")\n",
    "print(f\"모델 2 ({model_name_2})의 테스트 정확도: {accuracy_score(true_labels, np.argmax(logits2, axis=-1)):.4f}\")\n",
    "print(f\"앙상블 모델의 테스트 정확도 (소프트 보팅): {ensemble_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c910e31f",
   "metadata": {},
   "source": [
    "##### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ebcbf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(42000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_name_1 = \"kykim/bert-kor-base\"\n",
    "# model_path_1 = \"finetune-bert-kor\"\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(model_path_1, num_labels=num_labels)\n",
    "# model_tokenizer = AutoTokenizer.from_pretrained(\"kykim/bert-kor-base\")\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "81dbe937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=26, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_2 = \"BM-K/KoSimCSE-roberta\"\n",
    "model_path_2 = \"finetune-BM-K\"\n",
    "\n",
    "num_labels = data['label_id'].nunique()\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path_2, num_labels=num_labels)\n",
    "model_tokenizer = AutoTokenizer.from_pretrained(\"BM-K/KoSimCSE-roberta\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35e361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_label = data.copy()\n",
    "data_for_label.drop(['label_id'], axis=1, inplace=True) \n",
    "predict_dataset = Dataset.from_pandas(data_for_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "177b1a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 42924/42924 [00:04<00:00, 10517.43 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_fn_for_prediction(ex):\n",
    "    # label 칼럼이 없으므로 text 컬럼만 토큰화 진행\n",
    "    return model_tokenizer(ex[\"text\"], padding=\"max_length\", truncation=True, max_length=128) # max_length 조정 (128->512)\n",
    "\n",
    "predict_dataset = predict_dataset.map(tokenize_fn_for_prediction, batched=True)\n",
    "predict_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"]) # 라벨은 없으므로 제외\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2de947d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "예측된 로짓 형태: (42924, 26)\n"
     ]
    }
   ],
   "source": [
    "prediction_args = TrainingArguments(\n",
    "    output_dir=\"./prediction_output\", # 임시 출력 디렉토리\n",
    "    per_device_eval_batch_size=16, # 평가 배치 크기\n",
    "    do_train=False, # 학습은 안 함\n",
    "    do_predict=True, # 예측만 수행\n",
    "    report_to=\"none\", # W&B 등 로깅 비활성화\n",
    "    disable_tqdm=False, # 진행률 바 표시 (기본값 True)\n",
    ")\n",
    "\n",
    "# Trainer 인스턴스 생성\n",
    "# 이전에 학습에 사용한 compute_metrics 함수는 필요 X (라벨이 없으므로)\n",
    "trainer = Trainer(model=model, args=prediction_args)\n",
    "\n",
    "# 예측 수행\n",
    "predictions_output = trainer.predict(predict_dataset)\n",
    "\n",
    "# predictions_output 객체에서 로짓 추출\n",
    "logits = predictions_output.predictions\n",
    "print(f\"\\n예측된 로짓 형태: {logits.shape}\")\n",
    "\n",
    "# 로짓을 확률로 변환 (필요한 경우)\n",
    "probabilities = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "\n",
    "# 가장 높은 확률을 가진 라벨의 인덱스 추출\n",
    "predicted_class_indices = np.argmax(logits, axis=-1)\n",
    "\n",
    "# 라벨 인덱스를 실제 라벨 이름으로 매핑\n",
    "category_labels = [f'{i}' for i in range(num_labels)]\n",
    "predicted_label_names = [category_labels[idx] for idx in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69db9498",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_label['predicted_label'] = predicted_label_names\n",
    "data_for_label['predicted_label'] = data_for_label['predicted_label'].astype(int)\n",
    "predict1_accuracy = accuracy_score(data_for_label['label_id'], data_for_label['predicted_label'])\n",
    "print(predict1_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46ff75b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_id</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>휴가 돌려줘</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>관종들 릴스 리스타 그램 릴스 초보</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>날이 좋아서</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>행복했던 9월 고마워</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>협찬 동결건조야채 블록 1개로 13종의 보라 야채와 유산균 섭취 가능 보라색 안토시...</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42919</th>\n",
       "      <td>아름다운 색채의 향연, 수채화로 그려낸 풍경화.</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42920</th>\n",
       "      <td>예술가의 아침, 커피와 함께하는 스케치 시간.</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42921</th>\n",
       "      <td>디자인 스튜디오에서의 하루, 창의력 넘치는 공간.</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42922</th>\n",
       "      <td>도시의 밤을 담은 사진, 빛과 그림자의 조화.</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42923</th>\n",
       "      <td>미니어처 아트, 작은 세계 속에 담긴 큰 이야기.</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42924 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label_id  \\\n",
       "0                                                 휴가 돌려줘        19   \n",
       "1                                    관종들 릴스 리스타 그램 릴스 초보        21   \n",
       "2                                                 날이 좋아서        19   \n",
       "3                                            행복했던 9월 고마워        19   \n",
       "4      협찬 동결건조야채 블록 1개로 13종의 보라 야채와 유산균 섭취 가능 보라색 안토시...         8   \n",
       "...                                                  ...       ...   \n",
       "42919                         아름다운 색채의 향연, 수채화로 그려낸 풍경화.         8   \n",
       "42920                          예술가의 아침, 커피와 함께하는 스케치 시간.         8   \n",
       "42921                        디자인 스튜디오에서의 하루, 창의력 넘치는 공간.         8   \n",
       "42922                          도시의 밤을 담은 사진, 빛과 그림자의 조화.         8   \n",
       "42923                        미니어처 아트, 작은 세계 속에 담긴 큰 이야기.         8   \n",
       "\n",
       "       predicted_label  \n",
       "0                   19  \n",
       "1                   14  \n",
       "2                   19  \n",
       "3                   19  \n",
       "4                    8  \n",
       "...                ...  \n",
       "42919                8  \n",
       "42920                8  \n",
       "42921                8  \n",
       "42922                8  \n",
       "42923                8  \n",
       "\n",
       "[42924 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8a8d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_for_label.to_csv(\"tests/kykim_label_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2742ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_label.to_csv(\"tests/bm-k_label_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aa5bad02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, label_name in enumerate(category_labels):\n",
    "    data_for_label[f'prob_{label_name}'] = probabilities[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02fb9f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>휴가 돌려줘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>관종들 릴스 리스타 그램 릴스 초보</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>날이 좋아서</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>행복했던 9월 고마워</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>협찬 동결건조야채 블록 1개로 13종의 보라 야채와 유산균 섭취 가능 보라색 안토시...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                                             휴가 돌려줘\n",
       "1                                관종들 릴스 리스타 그램 릴스 초보\n",
       "2                                             날이 좋아서\n",
       "3                                        행복했던 9월 고마워\n",
       "4  협찬 동결건조야채 블록 1개로 13종의 보라 야채와 유산균 섭취 가능 보라색 안토시..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfb4212",
   "metadata": {},
   "source": [
    "ensemble model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58377b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_label = data.copy()\n",
    "data_for_label.drop(['label_id'], axis=1, inplace=True) \n",
    "predict_dataset = Dataset.from_pandas(data_for_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2613b751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(42000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_1 = \"kykim/bert-kor-base\"\n",
    "model_path_1 = \"finetune-bert-kor\"\n",
    "\n",
    "model1 = AutoModelForSequenceClassification.from_pretrained(model_path_1, num_labels=num_labels)\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94bcde6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=26, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_2 = \"BM-K/KoSimCSE-roberta\"\n",
    "model_path_2 = \"finetune-BM-K\"\n",
    "\n",
    "num_labels = data['label_id'].nunique()\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(model_path_2, num_labels=num_labels)\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc49784e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 42924/42924 [00:03<00:00, 10906.50 examples/s]\n",
      "Map: 100%|██████████| 42924/42924 [00:03<00:00, 11251.78 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 0.4. 각 모델에 맞는 토크나이저 로드 및 텍스트 토큰화 ---\n",
    "\n",
    "# kykim 모델용 토크나이저 및 데이터셋\n",
    "tokenizer_kykim = AutoTokenizer.from_pretrained(\"kykim/bert-kor-base\")\n",
    "def tokenize_fn_kykim_for_predict(examples):\n",
    "    return tokenizer_kykim(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "predict_dataset_kykim_tokenized = predict_dataset.map(tokenize_fn_kykim_for_predict, batched=True)\n",
    "predict_dataset_kykim_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "\n",
    "# KoSimCSE 모델용 토크나이저 및 데이터셋\n",
    "tokenizer_kosimcse = AutoTokenizer.from_pretrained(\"BM-K/KoSimCSE-roberta\")\n",
    "def tokenize_fn_kosimcse_for_predict(examples):\n",
    "    tokenized_output = tokenizer_kosimcse(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    if \"token_type_ids\" not in tokenized_output:\n",
    "        tokenized_output[\"token_type_ids\"] = [[0] * len(ids) for ids in tokenized_output[\"input_ids\"]]\n",
    "    return tokenized_output\n",
    "\n",
    "predict_dataset_kosimcse_tokenized = predict_dataset.map(tokenize_fn_kosimcse_for_predict, batched=True)\n",
    "predict_dataset_kosimcse_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\"])\n",
    "\n",
    "# --- 2. Trainer를 사용하여 각 모델의 예측 로짓(Logits) 얻기 ---\n",
    "# 더미 TrainingArguments (예측용이므로 대부분의 인자는 중요하지 않음)\n",
    "prediction_args = TrainingArguments(\n",
    "    output_dir=\"./voting_prediction_output\", # 임시 출력 디렉토리\n",
    "    per_device_eval_batch_size=16, # 평가 배치 크기\n",
    "    do_train=False,\n",
    "    do_predict=True,\n",
    "    report_to=\"none\", # W&B 등 로깅 비활성화\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "# Model 1 Prediction\n",
    "trainer1 = Trainer(model=model1, args=prediction_args)\n",
    "predictions1 = trainer1.predict(predict_dataset_kykim_tokenized)\n",
    "logits1 = predictions1.predictions # numpy array 형태의 로짓\n",
    "\n",
    "# Model 2 Prediction\n",
    "trainer2 = Trainer(model=model2, args=prediction_args)\n",
    "predictions2 = trainer2.predict(predict_dataset_kosimcse_tokenized)\n",
    "logits2 = predictions2.predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920852a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. 로짓(Logits) 또는 확률(Probabilities) 평균내기 ---\n",
    "# 소프트 보팅은 로짓 또는 softmax 확률을 평균낼 수 있음 (softmax는 비선형 변환이므로 평균 내기 전에 로짓 상태에서 평균 내는 것이 좋음)\n",
    "# 일반적으로 로짓을 평균내는 것이 더 안정적\n",
    "\n",
    "# 로짓 평균\n",
    "ensemble_logits = (logits1 + logits2) / 2 \n",
    "print(f\"\\n예측된 로짓 형태: {ensemble_logits.shape}\")\n",
    "\n",
    "# 로짓을 확률로 변환 (필요한 경우)\n",
    "probabilities = torch.softmax(torch.tensor(ensemble_logits), dim=-1).numpy()\n",
    "\n",
    "# 평균 로짓에서 최종 예측 클래스 선택\n",
    "ensemble_predictions = np.argmax(ensemble_logits, axis=-1)\n",
    "\n",
    "# 라벨 인덱스를 실제 라벨 이름으로 매핑\n",
    "category_labels = [f'{i}' for i in range(num_labels)]\n",
    "predicted_label_names = [category_labels[idx] for idx in ensemble_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0fa8f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8230127667505358\n"
     ]
    }
   ],
   "source": [
    "data_for_label['predicted_label'] = predicted_label_names\n",
    "data_for_label['predicted_label'] = data_for_label['predicted_label'].astype(int)\n",
    "predict_accuracy = accuracy_score(data['label_id'], data_for_label['predicted_label'])\n",
    "print(predict_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7f10af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_label.to_csv(\"tests/ensemble_label_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b8c409",
   "metadata": {},
   "source": [
    "##### Multi-column classification tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7147badb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae3668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccdaaa09",
   "metadata": {},
   "source": [
    "##### multi-label classification tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820f51fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f585fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model & toknizer loading\n",
    "\n",
    "model_name = \"kykim/bert-kor-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "\n",
    "## 모델이 bert 계열이고, 속도가 중요하면 BertTkenizerFast\n",
    "## 모델을 자주 비꾸거나 여러 모델 실험할 계획이면 AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d63003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface의 datasets.Dataset을 사용하는 방식\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train' : Dataset.from_pandas(train),\n",
    "    'test' : Dataset.from_pandas(test)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4994aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label_id', '__index_level_0__'],\n",
       "        num_rows: 34339\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label_id', '__index_level_0__'],\n",
       "        num_rows: 8585\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1fe0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 34339/34339 [00:08<00:00, 4135.53 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 문장 길이 통계 (토큰 기준):\n",
      "90th 퍼센타일: 227.0\n",
      "95th 퍼센타일: 282.0\n",
      "99th 퍼센타일: 425.0\n",
      "가장 긴 문장 길이 (Truncation 적용 후): 512\n"
     ]
    }
   ],
   "source": [
    "# max_length 최적화를 위해서 ids의 길이 확인\n",
    "# 길이 계산 함수 정의\n",
    "def get_tokenized_length(example):\n",
    "    # truncation=True를 통해 max_length를 초과하는 텍스트는 잘립니다.\n",
    "    # 모델에 실제로 들어갈 길이만 측정하는 것이 중요합니다.\n",
    "    # padding은 길이를 측정하는 단계에서는 필요하지 않으므로 사용하지 않습니다.\n",
    "    tokenized_output = tokenizer(example[\"text\"], truncation=True)\n",
    "    return {\"length\": len(tokenized_output[\"input_ids\"])}\n",
    "\n",
    "# dataset['train']의 'text' 컬럼에 대해 길이 계산\n",
    "# map 함수는 새로운 컬럼('length')을 추가하여 반환합니다.\n",
    "lengths_dataset = dataset[\"train\"].map(get_tokenized_length, batched=False, remove_columns=dataset[\"train\"].column_names)\n",
    "\n",
    "# 'length' 컬럼에서 모든 길이를 numpy 배열로 추출\n",
    "text_lengths = np.array(lengths_dataset['length'])\n",
    "\n",
    "# 퍼센타일 값 계산\n",
    "percentile_90 = np.percentile(text_lengths, 90)\n",
    "percentile_95 = np.percentile(text_lengths, 95)\n",
    "percentile_99 = np.percentile(text_lengths, 99)\n",
    "max_length_observed = np.max(text_lengths)\n",
    "\n",
    "print(f\"훈련 데이터 문장 길이 통계 (토큰 기준):\")\n",
    "print(f\"90th 퍼센타일: {percentile_90}\")\n",
    "print(f\"95th 퍼센타일: {percentile_95}\")\n",
    "print(f\"99th 퍼센타일: {percentile_99}\")\n",
    "print(f\"가장 긴 문장 길이 (Truncation 적용 후): {max_length_observed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834201f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['length'],\n",
       "    num_rows: 34339\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ea831",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 34339/34339 [00:06<00:00, 4912.45 examples/s]\n",
      "Map: 100%|██████████| 8585/8585 [00:01<00:00, 5272.43 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_fn(ex):\n",
    "    return tokenizer(ex[\"text\"], padding=\"max_length\", truncation=True, max_length=512) # max_length 조정\n",
    "\n",
    "dataset = dataset.map(tokenize_fn, batched=True)\n",
    "# dataset = dataset.rename_column(\"label_id\", \"label\")\n",
    "# dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505be22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/34339 [00:00<?, ? examples/s]C:\\Users\\ehddl\\AppData\\Local\\Temp\\ipykernel_24404\\843318086.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {\"label\": torch.tensor(example[\"label\"], dtype=torch.float)}\n",
      "Map: 100%|██████████| 34339/34339 [00:11<00:00, 2866.86 examples/s]\n",
      "Map: 100%|██████████| 8585/8585 [00:02<00:00, 2906.36 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# \"하나의 텍스트가 여러개의 라벨을 가질 수 있다\"는 전제 하에,\n",
    "# dataset['label_id'] 컬럼이 원래부터 각 샘플에 대해 [라벨_ID_1, 라벨_ID_2, ...] 와 같은 리스트 형태여야 합니다.\n",
    "# 만약 그렇지 않다면, 원본 데이터 로드 시점부터 멀티라벨 형태가 되도록 전처리해야 합니다.\n",
    "\n",
    "# 예시: dataset['train']에 있는 모든 'label_id' 리스트를 평탄화하여 고유 라벨 추출 (멀티라벨이 이미 리스트 형태로 주어졌다고 가정)\n",
    "all_labels = set()\n",
    "for split in dataset.keys(): # train, test 등 모든 스플릿\n",
    "    for example in dataset[split]:\n",
    "        # 'label_id'가 단일 정수형이라도 여기에 추가합니다.\n",
    "        # 실제 MultiLabelBinarizer는 라벨의 집합을 필요로 합니다.\n",
    "        if isinstance(example['label_id'], list):\n",
    "            all_labels.update(example['label_id'])\n",
    "        else: # 단일 정수형 라벨인 경우\n",
    "            all_labels.add(example['label_id'])\n",
    "\n",
    "# 정렬하여 MultiLabelBinarizer에 전달 (순서 일관성 유지)\n",
    "unique_labels = sorted(list(all_labels))\n",
    "num_total_labels = len(unique_labels) # 27개가 맞는지 확인\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=unique_labels)\n",
    "\n",
    "# 라벨을 멀티라벨 이진 벡터로 변환\n",
    "def convert_to_multilabel_format(example):\n",
    "    # example['label_id']가 [0, 1, 3]과 같이 여러 라벨 ID를 포함하는 리스트라고 가정합니다.\n",
    "    # 만약 dataset['label_id']가 여전히 단일 정수(멀티클래스)라면, 이 부분의 로직을 변경해야 합니다.\n",
    "    # (예: 단일 정수를 가진 리스트로 만들고 binarize)\n",
    "\n",
    "    # 텍스트에 할당된 라벨 ID들을 MLB를 통해 이진 벡터로 변환\n",
    "    # input for mlb.fit_transform should be a list of lists (or a list of sets)\n",
    "    # 각 샘플의 'label_id'가 이미 리스트 형태여야 합니다.\n",
    "    # 만약 'label_id'가 단일 정수라면, `[example['label_id']]` 와 같이 리스트로 감싸줘야 합니다.\n",
    "    \n",
    "    # 예시: example['label_id']가 [1, 5, 10] 또는 5 와 같이 올 수 있다고 가정\n",
    "    labels_to_binarize = example['label_id']\n",
    "    if not isinstance(labels_to_binarize, list):\n",
    "        labels_to_binarize = [labels_to_binarize] # 단일 라벨도 리스트로 감싸서 처리\n",
    "\n",
    "    multilabel_vector = mlb.fit_transform([labels_to_binarize])[0]\n",
    "    \n",
    "    # PyTorch 모델에 전달하기 위해 FloatTensor로 변환\n",
    "    return {\"label\": torch.tensor(multilabel_vector, dtype=torch.float)}\n",
    "\n",
    "# 데이터셋의 'label_id' 컬럼을 멀티라벨 이진 벡터로 변환하고 'label' 컬럼으로 대체\n",
    "dataset = dataset.map(convert_to_multilabel_format, batched=False)\n",
    "\n",
    "# 4. 데이터셋 포맷 설정 (여기서 한 번만)\n",
    "# 모든 필요한 컬럼이 포함되었는지 확인하고 'label' 컬럼의 타입을 torch.float으로 설정\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cebf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 초기화 시 num_labels 설정\n",
    "# num_total_labels는 MultiLabelBinarizer에 사용된 고유 라벨의 총 개수입니다.\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_total_labels, # 27개여야 함\n",
    "    use_safetensors=True\n",
    ")\n",
    "\n",
    "# (Trainer 설정 및 학습은 이전과 동일)\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b702681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting trainer\n",
    "# !pip install accelerate>=0.26.0\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"finetune-bert-kor\",\n",
    "    eval_strategy=\"epoch\", # evaluation_strategy -> eval_strategy\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    save_total_limit=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aad7086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(axis=-1)\n",
    "    labels = p.label_ids\n",
    "    return {\"accuracy\": accuracy_score(labels, preds)}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3390e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6441' max='6441' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6441/6441 50:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.975700</td>\n",
       "      <td>0.933468</td>\n",
       "      <td>0.736517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.747100</td>\n",
       "      <td>0.900717</td>\n",
       "      <td>0.746418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.622600</td>\n",
       "      <td>0.917289</td>\n",
       "      <td>0.751427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6441, training_loss=0.8551019856026965, metrics={'train_runtime': 3027.2064, 'train_samples_per_second': 34.03, 'train_steps_per_second': 2.128, 'total_flos': 6777688081890816.0, 'train_loss': 0.8551019856026965, 'epoch': 3.0})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a52872",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "69557889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(42000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델과 토크나이저 로드\n",
    "model_path = \"finetune-bert-kor/\"  # 저장된 모델 디렉토리\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# 모델을 평가 모드로 전환\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374023f4",
   "metadata": {},
   "source": [
    "##### Using Pytorch (pre-trained model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823d0c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # huggingface가 아니라 pytorch library 사용 시 방법\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# class TokenDataset(Dataset):\n",
    "  \n",
    "#     def __init__(self, dataframe, model_name):\n",
    "#         # sentence, label 컬럼으로 구성된 데이터프레임 전달\n",
    "#         self.data = dataframe        \n",
    "#         # Huggingface 토크나이저 생성\n",
    "#         # self.tokenizer = BertTokenizerFast.from_pretrained(tokenizer_pretrained)\n",
    "#         self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "  \n",
    "#     def __len__(self):\n",
    "#         return len(self.data)\n",
    "  \n",
    "#     def __getitem__(self, idx):\n",
    "#         sentence = self.data.iloc[idx]['document']\n",
    "#         label = self.data.iloc[idx]['label']\n",
    "\n",
    "#         # 토큰화 처리\n",
    "#         tokens = self.tokenizer(\n",
    "#             sentence,                \n",
    "#             return_tensors='pt',     \n",
    "#             truncation=True,        \n",
    "#             padding='max_length',    \n",
    "#             add_special_tokens=True  \n",
    "#         )\n",
    "\n",
    "#         input_ids = tokens['input_ids'].squeeze(0)           # 2D -> 1D\n",
    "#         attention_mask = tokens['attention_mask'].squeeze(0) # 2D -> 1D\n",
    "#         token_type_ids = torch.zeros_like(attention_mask)\n",
    "\n",
    "#         return {\n",
    "#             'input_ids': input_ids,\n",
    "#             'attention_mask': attention_mask, \n",
    "#             'token_type_ids': token_type_ids,}, torch.tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaae1057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train, test 데이터셋 생성\n",
    "# train_data = TokenDataset(train, model_name)\n",
    "# test_data = TokenDataset(test, model_name)\n",
    "\n",
    "# train_loader = DataLoader(train_data, batch_size=8, shuffle=True, num_workers=8)\n",
    "# test_loader = DataLoader(test_data, batch_size=8, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c291e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1개의 batch 꺼내기\n",
    "# inputs, labels = next(iter(train_loader))\n",
    "\n",
    "# # 데이터셋을 device 설정\n",
    "# inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "# labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe6553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pad_token 없을 경우 대비\n",
    "# if tokenizer.pad_token is None:\n",
    "#     tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "#     model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# def predict_label(text_list):\n",
    "#     inputs = tokenizer(text_list, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#         preds = torch.argmax(outputs.logits, dim=1)\n",
    "#     return preds.tolist()\n",
    "\n",
    "# # def predict_label(text_list):\n",
    "# #     inputs = tokenizer(text_list, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
    "# #     with torch.no_grad():\n",
    "# #         outputs = model(**inputs)\n",
    "# #     probs = softmax(outputs.logits, dim=1)\n",
    "# #     pred_idx = torch.argmax(probs, dim=1).item()\n",
    "# #     return label_list[pred_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32104b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# texts = data['text'].tolist()\n",
    "# batch_size = 16  # 상황에 따라 조절\n",
    "\n",
    "# all_preds = []\n",
    "# for i in tqdm(range(0, len(texts), batch_size), desc=\"Predicting\", ncols=100):\n",
    "#     batch_texts = texts[i:i+batch_size]\n",
    "#     inputs = tokenizer(batch_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "#     inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs)\n",
    "#         preds = torch.argmax(outputs.logits, dim=1)\n",
    "    \n",
    "#     all_preds.extend(preds.cpu().tolist())\n",
    "\n",
    "# # 결과를 데이터프레임에 추가\n",
    "# data['bert_label'] = all_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sns-categorizer-wO1G7-CE-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
