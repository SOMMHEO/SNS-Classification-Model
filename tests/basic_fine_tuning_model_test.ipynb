{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6b3b1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ehddl\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\sns-categorizer-wO1G7-CE-py3.11\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "# from torch.utils.data import Dataset, DataLoader -> datasets ë¼ì´ë¸ŒëŸ¬ë¦¬ë‘ ì¶©ëŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddf5128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/ehddl/Desktop/ì—…ë¬´/code/sns-categorizer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3695b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_parquet(\"C:/Users/ehddl/Downloads/merged_data.parquet\")\n",
    "new_data = new_data[['media_cn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fd81671",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b493133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    \n",
    "    text = emoji.replace_emoji(text, replace='')\n",
    "    text = re.sub(r'[^ê°€-í£a-zA-Z0-9\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98f72e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['media_cn_cleaned'] = new_data['media_cn'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f47aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data[~new_data.apply(lambda row: row.astype(str).str.strip().eq('').any(), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a75c244c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media_cn</th>\n",
       "      <th>media_cn_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YJM* will Drop a new album in the hottest summ...</td>\n",
       "      <td>yjm will drop a new album in the hottest summer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ë§ˆì§€ë§‰ì— ë¬´ì„œìš´ ì‚¬ì§„ì´ ë‚˜ì˜µë‹ˆë‹¤â€¦.ğŸ˜±\\nì´íƒœë¦¬ ê³µí•­ì—ì„œ ë§ˆë¬´ë¦¬ ë„ë„ˆì¸  ê¹Œì§€\\në§›ìˆìœ¼...</td>\n",
       "      <td>ë§ˆì§€ë§‰ì— ë¬´ì„œìš´ ì‚¬ì§„ì´ ë‚˜ì˜µë‹ˆë‹¤ ì´íƒœë¦¬ ê³µí•­ì—ì„œ ë§ˆë¬´ë¦¬ ë„ë„ˆì¸  ê¹Œì§€ ë§›ìˆìœ¼ë©´ 0ì¹¼ë¡œ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>â€¦\\nì•ˆë…•í•˜ì„¸ìš”.\\nê° ë¯¸ì‚¬ ì…ë‹ˆë‹¤.\\nê°€ì„ì´ë„¤ìš”â€¦â€¦. \\nì € ì˜ ìµì—ˆìŠµë‹ˆë‹¤.\\në¹¨...</td>\n",
       "      <td>ì•ˆë…•í•˜ì„¸ìš” ê° ë¯¸ì‚¬ ì…ë‹ˆë‹¤ ê°€ì„ì´ë„¤ìš” ì € ì˜ ìµì—ˆìŠµë‹ˆë‹¤ ë¹¨ë¦¬ ìˆ˜í™•í•´ ì£¼ì§€ ì•Šìœ¼ë©´ ì©...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>í‘¸ë“œíŠ¸ëŸ­ìœ¼ë¡œ ì˜¤ëŠ”ë° ì—¬ê¸° ìˆœëŒ€ ë„ˆë¬´ ë§›ìˆì–´!!!\\nì•¼ì±„ê°€ë“!!! ì—¬ê¸° ìˆœëŒ€ê°€ ì€ê·¼ ...</td>\n",
       "      <td>í‘¸ë“œíŠ¸ëŸ­ìœ¼ë¡œ ì˜¤ëŠ”ë° ì—¬ê¸° ìˆœëŒ€ ë„ˆë¬´ ë§›ìˆì–´ ì•¼ì±„ê°€ë“ ì—¬ê¸° ìˆœëŒ€ê°€ ì€ê·¼ ë§›ìˆì–´ì„œ ì¤‘ë…...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#ì œí’ˆí˜‘ì°¬\\n\\në§¤ì¼ë§¤ì¼ ì •ì„±ìœ¼ë¡œ ì§ì ‘ ë§Œë“œëŠ” #í‘ì„ìì¸ì ˆë¯¸\\nì²­ë…„ë–¡ì§‘ ëª…ë¡€í—Œ ì‹œê·¸...</td>\n",
       "      <td>ì œí’ˆí˜‘ì°¬ ë§¤ì¼ë§¤ì¼ ì •ì„±ìœ¼ë¡œ ì§ì ‘ ë§Œë“œëŠ” í‘ì„ìì¸ì ˆë¯¸ ì²­ë…„ë–¡ì§‘ ëª…ë¡€í—Œ ì‹œê·¸ë‹ˆì²˜ ì œí’ˆ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19615</th>\n",
       "      <td>KiiiKiii with #SSGëœë”ìŠ¤â¤ï¸\\n\\n#KiiiKiii #í‚¤í‚¤ \\n#SU...</td>\n",
       "      <td>kiiikiii with ssgëœë”ìŠ¤ kiiikiii í‚¤í‚¤ sui ìˆ˜ì´</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19616</th>\n",
       "      <td>#í˜‘ì°¬ ì¹¨êµ¬ ë°”ê¿¨ë”ë‹ˆ í˜¸í…”ê°™ëŒ€ìš”ğŸ©µ\\n\\nì ê¹ ì‚¬ëŠ” êµ°ì¸ê´€ì‚¬ì´ì§€ë§Œ ê¹”ê¿ˆí•˜ê²Œ ì‚´êµ¬ì‹¶ì–´....</td>\n",
       "      <td>í˜‘ì°¬ ì¹¨êµ¬ ë°”ê¿¨ë”ë‹ˆ í˜¸í…”ê°™ëŒ€ìš” ì ê¹ ì‚¬ëŠ” êµ°ì¸ê´€ì‚¬ì´ì§€ë§Œ ê¹”ê¿ˆí•˜ê²Œ ì‚´êµ¬ì‹¶ì–´ ë‚˜ì¤‘ì— ì´...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19617</th>\n",
       "      <td>#ê³µêµ¬ì˜ˆê³  duri.official \\n\\nğŸ“¢ê³µêµ¬ ì•ˆí•˜ëŠ” ë¸Œëœë“œ ë‘ë¦¬\\nì¼ˆë¦¬ë§˜ì´ ìµœ...</td>\n",
       "      <td>ê³µêµ¬ì˜ˆê³  duriofficial ê³µêµ¬ ì•ˆí•˜ëŠ” ë¸Œëœë“œ ë‘ë¦¬ ì¼ˆë¦¬ë§˜ì´ ìµœì´ˆë¡œ ê³µêµ¬ ìµœì €...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19618</th>\n",
       "      <td>â€¢ clearance sale last day ! â€¢ \\n\\nê¸ˆì¼ ë°¤ 11ì‹œ 55ë¶„...</td>\n",
       "      <td>clearance sale last day ê¸ˆì¼ ë°¤ 11ì‹œ 55ë¶„ í´ë¦¬ì–´ëŸ°ìŠ¤ ì„¸ì¼ì´...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19619</th>\n",
       "      <td>â€¢congratulation!â€¢\\nì—¬ë¦„ì‹œì¦Œ 1ì°¨ë“œë¡­ ì´ë²¤íŠ¸ ë‹¹ì²¨ìë¥¼ ë°œí‘œí•©ë‹ˆë‹¤ ğŸŒ´\\...</td>\n",
       "      <td>congratulation ì—¬ë¦„ì‹œì¦Œ 1ì°¨ë“œë¡­ ì´ë²¤íŠ¸ ë‹¹ì²¨ìë¥¼ ë°œí‘œí•©ë‹ˆë‹¤ ì˜¤ëŠ˜ ì˜¤ì „ì—...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18282 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                media_cn  \\\n",
       "0      YJM* will Drop a new album in the hottest summ...   \n",
       "1      ë§ˆì§€ë§‰ì— ë¬´ì„œìš´ ì‚¬ì§„ì´ ë‚˜ì˜µë‹ˆë‹¤â€¦.ğŸ˜±\\nì´íƒœë¦¬ ê³µí•­ì—ì„œ ë§ˆë¬´ë¦¬ ë„ë„ˆì¸  ê¹Œì§€\\në§›ìˆìœ¼...   \n",
       "2      â€¦\\nì•ˆë…•í•˜ì„¸ìš”.\\nê° ë¯¸ì‚¬ ì…ë‹ˆë‹¤.\\nê°€ì„ì´ë„¤ìš”â€¦â€¦. \\nì € ì˜ ìµì—ˆìŠµë‹ˆë‹¤.\\në¹¨...   \n",
       "3      í‘¸ë“œíŠ¸ëŸ­ìœ¼ë¡œ ì˜¤ëŠ”ë° ì—¬ê¸° ìˆœëŒ€ ë„ˆë¬´ ë§›ìˆì–´!!!\\nì•¼ì±„ê°€ë“!!! ì—¬ê¸° ìˆœëŒ€ê°€ ì€ê·¼ ...   \n",
       "4      #ì œí’ˆí˜‘ì°¬\\n\\në§¤ì¼ë§¤ì¼ ì •ì„±ìœ¼ë¡œ ì§ì ‘ ë§Œë“œëŠ” #í‘ì„ìì¸ì ˆë¯¸\\nì²­ë…„ë–¡ì§‘ ëª…ë¡€í—Œ ì‹œê·¸...   \n",
       "...                                                  ...   \n",
       "19615  KiiiKiii with #SSGëœë”ìŠ¤â¤ï¸\\n\\n#KiiiKiii #í‚¤í‚¤ \\n#SU...   \n",
       "19616  #í˜‘ì°¬ ì¹¨êµ¬ ë°”ê¿¨ë”ë‹ˆ í˜¸í…”ê°™ëŒ€ìš”ğŸ©µ\\n\\nì ê¹ ì‚¬ëŠ” êµ°ì¸ê´€ì‚¬ì´ì§€ë§Œ ê¹”ê¿ˆí•˜ê²Œ ì‚´êµ¬ì‹¶ì–´....   \n",
       "19617  #ê³µêµ¬ì˜ˆê³  duri.official \\n\\nğŸ“¢ê³µêµ¬ ì•ˆí•˜ëŠ” ë¸Œëœë“œ ë‘ë¦¬\\nì¼ˆë¦¬ë§˜ì´ ìµœ...   \n",
       "19618  â€¢ clearance sale last day ! â€¢ \\n\\nê¸ˆì¼ ë°¤ 11ì‹œ 55ë¶„...   \n",
       "19619  â€¢congratulation!â€¢\\nì—¬ë¦„ì‹œì¦Œ 1ì°¨ë“œë¡­ ì´ë²¤íŠ¸ ë‹¹ì²¨ìë¥¼ ë°œí‘œí•©ë‹ˆë‹¤ ğŸŒ´\\...   \n",
       "\n",
       "                                        media_cn_cleaned  \n",
       "0        yjm will drop a new album in the hottest summer  \n",
       "1      ë§ˆì§€ë§‰ì— ë¬´ì„œìš´ ì‚¬ì§„ì´ ë‚˜ì˜µë‹ˆë‹¤ ì´íƒœë¦¬ ê³µí•­ì—ì„œ ë§ˆë¬´ë¦¬ ë„ë„ˆì¸  ê¹Œì§€ ë§›ìˆìœ¼ë©´ 0ì¹¼ë¡œ...  \n",
       "2      ì•ˆë…•í•˜ì„¸ìš” ê° ë¯¸ì‚¬ ì…ë‹ˆë‹¤ ê°€ì„ì´ë„¤ìš” ì € ì˜ ìµì—ˆìŠµë‹ˆë‹¤ ë¹¨ë¦¬ ìˆ˜í™•í•´ ì£¼ì§€ ì•Šìœ¼ë©´ ì©...  \n",
       "3      í‘¸ë“œíŠ¸ëŸ­ìœ¼ë¡œ ì˜¤ëŠ”ë° ì—¬ê¸° ìˆœëŒ€ ë„ˆë¬´ ë§›ìˆì–´ ì•¼ì±„ê°€ë“ ì—¬ê¸° ìˆœëŒ€ê°€ ì€ê·¼ ë§›ìˆì–´ì„œ ì¤‘ë…...  \n",
       "4      ì œí’ˆí˜‘ì°¬ ë§¤ì¼ë§¤ì¼ ì •ì„±ìœ¼ë¡œ ì§ì ‘ ë§Œë“œëŠ” í‘ì„ìì¸ì ˆë¯¸ ì²­ë…„ë–¡ì§‘ ëª…ë¡€í—Œ ì‹œê·¸ë‹ˆì²˜ ì œí’ˆ ...  \n",
       "...                                                  ...  \n",
       "19615            kiiikiii with ssgëœë”ìŠ¤ kiiikiii í‚¤í‚¤ sui ìˆ˜ì´  \n",
       "19616  í˜‘ì°¬ ì¹¨êµ¬ ë°”ê¿¨ë”ë‹ˆ í˜¸í…”ê°™ëŒ€ìš” ì ê¹ ì‚¬ëŠ” êµ°ì¸ê´€ì‚¬ì´ì§€ë§Œ ê¹”ê¿ˆí•˜ê²Œ ì‚´êµ¬ì‹¶ì–´ ë‚˜ì¤‘ì— ì´...  \n",
       "19617  ê³µêµ¬ì˜ˆê³  duriofficial ê³µêµ¬ ì•ˆí•˜ëŠ” ë¸Œëœë“œ ë‘ë¦¬ ì¼ˆë¦¬ë§˜ì´ ìµœì´ˆë¡œ ê³µêµ¬ ìµœì €...  \n",
       "19618  clearance sale last day ê¸ˆì¼ ë°¤ 11ì‹œ 55ë¶„ í´ë¦¬ì–´ëŸ°ìŠ¤ ì„¸ì¼ì´...  \n",
       "19619  congratulation ì—¬ë¦„ì‹œì¦Œ 1ì°¨ë“œë¡­ ì´ë²¤íŠ¸ ë‹¹ì²¨ìë¥¼ ë°œí‘œí•©ë‹ˆë‹¤ ì˜¤ëŠ˜ ì˜¤ì „ì—...  \n",
       "\n",
       "[18282 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4810aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 26\n",
    "new = new_data.drop(['media_cn'], axis=1)\n",
    "predict_dataset = Dataset.from_pandas(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebe924e",
   "metadata": {},
   "source": [
    "single model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55177d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(42000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=26, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_1 = \"kykim/bert-kor-base\"\n",
    "model_path_1 = \"finetune-bert-kor\"\n",
    "\n",
    "model1 = AutoModelForSequenceClassification.from_pretrained(model_path_1, num_labels=num_labels)\n",
    "model1_tokenizer = AutoTokenizer.from_pretrained(\"kykim/bert-kor-base\")\n",
    "model1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "432cfdf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=26, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_2 = \"BM-K/KoSimCSE-roberta\"\n",
    "model_path_2 = \"finetune-BM-K\"\n",
    "\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(model_path_2, num_labels=num_labels)\n",
    "model2_tokenizer = AutoTokenizer.from_pretrained(\"BM-K/KoSimCSE-roberta\")\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23f192e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = new_data.drop(['media_cn'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b13ee8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dataset = Dataset.from_pandas(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a50f982b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18981/18981 [00:01<00:00, 10980.10 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_fn_for_prediction(ex):\n",
    "    # label ì¹¼ëŸ¼ì´ ì—†ìœ¼ë¯€ë¡œ text ì»¬ëŸ¼ë§Œ í† í°í™” ì§„í–‰\n",
    "    return model1_tokenizer(ex[\"media_cn_cleaned\"], padding=\"max_length\", truncation=True, max_length=128) # max_length ì¡°ì • (128->512)\n",
    "\n",
    "predict_dataset = predict_dataset.map(tokenize_fn_for_prediction, batched=True)\n",
    "predict_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"]) # ë¼ë²¨ì€ ì—†ìœ¼ë¯€ë¡œ ì œì™¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d43d00c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18981/18981 [00:01<00:00, 12261.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# def tokenize_fn_for_prediction(ex):\n",
    "#     tokenized_output = model2_tokenizer(ex[\"media_cn_cleaned\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "#     if \"token_type_ids\" not in tokenized_output:\n",
    "#         tokenized_output[\"token_type_ids\"] = [[0] * len(ids) for ids in tokenized_output[\"input_ids\"]]\n",
    "#     return tokenized_output\n",
    "\n",
    "# predict_dataset = predict_dataset.map(tokenize_fn_for_prediction, batched=True)\n",
    "# predict_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\"]) # ë¼ë²¨ì€ ì—†ìœ¼ë¯€ë¡œ ì œì™¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eedf5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì˜ˆì¸¡ëœ ë¡œì§“ í˜•íƒœ: (18981, 26)\n"
     ]
    }
   ],
   "source": [
    "prediction_args = TrainingArguments(\n",
    "    output_dir=\"./prediction_output\", # ì„ì‹œ ì¶œë ¥ ë””ë ‰í† ë¦¬\n",
    "    per_device_eval_batch_size=16, # í‰ê°€ ë°°ì¹˜ í¬ê¸°\n",
    "    do_train=False, # í•™ìŠµì€ ì•ˆ í•¨\n",
    "    do_predict=True, # ì˜ˆì¸¡ë§Œ ìˆ˜í–‰\n",
    "    report_to=\"none\", # W&B ë“± ë¡œê¹… ë¹„í™œì„±í™”\n",
    "    disable_tqdm=False, # ì§„í–‰ë¥  ë°” í‘œì‹œ (ê¸°ë³¸ê°’ True)\n",
    ")\n",
    "\n",
    "# Trainer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "trainer = Trainer(model=model1, args=prediction_args) # ëª¨ë¸ ë³€ê²½\n",
    "\n",
    "# ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "predictions_output = trainer.predict(predict_dataset)\n",
    "\n",
    "# predictions_output ê°ì²´ì—ì„œ ë¡œì§“ ì¶”ì¶œ\n",
    "logits = predictions_output.predictions\n",
    "print(f\"\\nì˜ˆì¸¡ëœ ë¡œì§“ í˜•íƒœ: {logits.shape}\")\n",
    "\n",
    "# ë¡œì§“ì„ í™•ë¥ ë¡œ ë³€í™˜ (í•„ìš”í•œ ê²½ìš°)\n",
    "probabilities = torch.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "\n",
    "# ê°€ì¥ ë†’ì€ í™•ë¥ ì„ ê°€ì§„ ë¼ë²¨ì˜ ì¸ë±ìŠ¤ ì¶”ì¶œ\n",
    "predicted_class_indices = np.argmax(logits, axis=-1)\n",
    "\n",
    "# ë¼ë²¨ ì¸ë±ìŠ¤ë¥¼ ì‹¤ì œ ë¼ë²¨ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘\n",
    "category_labels = [f'{i}' for i in range(num_labels)]\n",
    "predicted_label_names = [category_labels[idx] for idx in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b3e832",
   "metadata": {},
   "source": [
    "ensemble predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "593bfd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18282/18282 [00:01<00:00, 12194.43 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18282/18282 [00:01<00:00, 12330.75 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 0.4. ê° ëª¨ë¸ì— ë§ëŠ” í† í¬ë‚˜ì´ì € ë¡œë“œ ë° í…ìŠ¤íŠ¸ í† í°í™” ---\n",
    "\n",
    "# kykim ëª¨ë¸ìš© í† í¬ë‚˜ì´ì € ë° ë°ì´í„°ì…‹\n",
    "model_name_1 = \"kykim/bert-kor-base\"\n",
    "model_path_1 = \"finetune-bert-kor\"\n",
    "model1 = AutoModelForSequenceClassification.from_pretrained(model_path_1, num_labels=num_labels)\n",
    "model1.eval()\n",
    "\n",
    "tokenizer_kykim = AutoTokenizer.from_pretrained(model_name_1)\n",
    "def tokenize_fn_kykim_for_predict(examples):\n",
    "    return tokenizer_kykim(examples[\"media_cn_cleaned\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "predict_dataset_kykim_tokenized = predict_dataset.map(tokenize_fn_kykim_for_predict, batched=True)\n",
    "predict_dataset_kykim_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "\n",
    "# KoSimCSE ëª¨ë¸ìš© í† í¬ë‚˜ì´ì € ë° ë°ì´í„°ì…‹\n",
    "model_name_2 = \"BM-K/KoSimCSE-roberta\"\n",
    "model_path_2 = \"finetune-BM-K\"\n",
    "\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(model_path_2, num_labels=num_labels)\n",
    "model2.eval()\n",
    "\n",
    "tokenizer_kosimcse = AutoTokenizer.from_pretrained(model_name_2)\n",
    "def tokenize_fn_kosimcse_for_predict(examples):\n",
    "    tokenized_output = tokenizer_kosimcse(examples[\"media_cn_cleaned\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "    if \"token_type_ids\" not in tokenized_output:\n",
    "        tokenized_output[\"token_type_ids\"] = [[0] * len(ids) for ids in tokenized_output[\"input_ids\"]]\n",
    "    return tokenized_output\n",
    "\n",
    "predict_dataset_kosimcse_tokenized = predict_dataset.map(tokenize_fn_kosimcse_for_predict, batched=True)\n",
    "predict_dataset_kosimcse_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"token_type_ids\"])\n",
    "\n",
    "# --- 2. Trainerë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ ë¡œì§“(Logits) ì–»ê¸° ---\n",
    "# ë”ë¯¸ TrainingArguments (ì˜ˆì¸¡ìš©ì´ë¯€ë¡œ ëŒ€ë¶€ë¶„ì˜ ì¸ìëŠ” ì¤‘ìš”í•˜ì§€ ì•ŠìŒ)\n",
    "prediction_args = TrainingArguments(\n",
    "    output_dir=\"./voting_prediction_output\", # ì„ì‹œ ì¶œë ¥ ë””ë ‰í† ë¦¬\n",
    "    per_device_eval_batch_size=16, # í‰ê°€ ë°°ì¹˜ í¬ê¸°\n",
    "    do_train=False,\n",
    "    do_predict=True,\n",
    "    report_to=\"none\", # W&B ë“± ë¡œê¹… ë¹„í™œì„±í™”\n",
    "    remove_unused_columns=False\n",
    ")\n",
    "\n",
    "# Model 1 Prediction\n",
    "trainer1 = Trainer(model=model1, args=prediction_args)\n",
    "predictions1 = trainer1.predict(predict_dataset_kykim_tokenized)\n",
    "logits1 = predictions1.predictions # numpy array í˜•íƒœì˜ ë¡œì§“\n",
    "\n",
    "# Model 2 Prediction\n",
    "trainer2 = Trainer(model=model2, args=prediction_args)\n",
    "predictions2 = trainer2.predict(predict_dataset_kosimcse_tokenized)\n",
    "logits2 = predictions2.predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d22c2534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì˜ˆì¸¡ëœ ë¡œì§“ í˜•íƒœ: (18282, 26)\n"
     ]
    }
   ],
   "source": [
    "# --- 3. ë¡œì§“(Logits) ë˜ëŠ” í™•ë¥ (Probabilities) í‰ê· ë‚´ê¸° ---\n",
    "# ì†Œí”„íŠ¸ ë³´íŒ…ì€ ë¡œì§“ ë˜ëŠ” softmax í™•ë¥ ì„ í‰ê· ë‚¼ ìˆ˜ ìˆìŒ (softmaxëŠ” ë¹„ì„ í˜• ë³€í™˜ì´ë¯€ë¡œ í‰ê·  ë‚´ê¸° ì „ì— ë¡œì§“ ìƒíƒœì—ì„œ í‰ê·  ë‚´ëŠ” ê²ƒì´ ì¢‹ìŒ)\n",
    "# ì¼ë°˜ì ìœ¼ë¡œ ë¡œì§“ì„ í‰ê· ë‚´ëŠ” ê²ƒì´ ë” ì•ˆì •ì \n",
    "\n",
    "# ë¡œì§“ í‰ê· \n",
    "ensemble_logits = (logits1 + logits2) / 2 \n",
    "print(f\"\\nì˜ˆì¸¡ëœ ë¡œì§“ í˜•íƒœ: {ensemble_logits.shape}\")\n",
    "\n",
    "# ë¡œì§“ì„ í™•ë¥ ë¡œ ë³€í™˜ (í•„ìš”í•œ ê²½ìš°)\n",
    "probabilities = torch.softmax(torch.tensor(ensemble_logits), dim=-1).numpy()\n",
    "\n",
    "# í‰ê·  ë¡œì§“ì—ì„œ ìµœì¢… ì˜ˆì¸¡ í´ë˜ìŠ¤ ì„ íƒ\n",
    "ensemble_predictions = np.argmax(ensemble_logits, axis=-1)\n",
    "\n",
    "# ë¼ë²¨ ì¸ë±ìŠ¤ë¥¼ ì‹¤ì œ ë¼ë²¨ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘\n",
    "category_labels = [f'{i}' for i in range(num_labels)]\n",
    "predicted_label_names = [category_labels[idx] for idx in ensemble_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57638bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new['predicted_label'] = predicted_label_names\n",
    "new['predicted_label'] = new['predicted_label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a1b40ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>media_cn_cleaned</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yjm will drop a new album in the hottest summer</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ë§ˆì§€ë§‰ì— ë¬´ì„œìš´ ì‚¬ì§„ì´ ë‚˜ì˜µë‹ˆë‹¤ ì´íƒœë¦¬ ê³µí•­ì—ì„œ ë§ˆë¬´ë¦¬ ë„ë„ˆì¸  ê¹Œì§€ ë§›ìˆìœ¼ë©´ 0ì¹¼ë¡œ...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ì•ˆë…•í•˜ì„¸ìš” ê° ë¯¸ì‚¬ ì…ë‹ˆë‹¤ ê°€ì„ì´ë„¤ìš” ì € ì˜ ìµì—ˆìŠµë‹ˆë‹¤ ë¹¨ë¦¬ ìˆ˜í™•í•´ ì£¼ì§€ ì•Šìœ¼ë©´ ì©...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>í‘¸ë“œíŠ¸ëŸ­ìœ¼ë¡œ ì˜¤ëŠ”ë° ì—¬ê¸° ìˆœëŒ€ ë„ˆë¬´ ë§›ìˆì–´ ì•¼ì±„ê°€ë“ ì—¬ê¸° ìˆœëŒ€ê°€ ì€ê·¼ ë§›ìˆì–´ì„œ ì¤‘ë…...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ì œí’ˆí˜‘ì°¬ ë§¤ì¼ë§¤ì¼ ì •ì„±ìœ¼ë¡œ ì§ì ‘ ë§Œë“œëŠ” í‘ì„ìì¸ì ˆë¯¸ ì²­ë…„ë–¡ì§‘ ëª…ë¡€í—Œ ì‹œê·¸ë‹ˆì²˜ ì œí’ˆ ...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19615</th>\n",
       "      <td>kiiikiii with ssgëœë”ìŠ¤ kiiikiii í‚¤í‚¤ sui ìˆ˜ì´</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19616</th>\n",
       "      <td>í˜‘ì°¬ ì¹¨êµ¬ ë°”ê¿¨ë”ë‹ˆ í˜¸í…”ê°™ëŒ€ìš” ì ê¹ ì‚¬ëŠ” êµ°ì¸ê´€ì‚¬ì´ì§€ë§Œ ê¹”ê¿ˆí•˜ê²Œ ì‚´êµ¬ì‹¶ì–´ ë‚˜ì¤‘ì— ì´...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19617</th>\n",
       "      <td>ê³µêµ¬ì˜ˆê³  duriofficial ê³µêµ¬ ì•ˆí•˜ëŠ” ë¸Œëœë“œ ë‘ë¦¬ ì¼ˆë¦¬ë§˜ì´ ìµœì´ˆë¡œ ê³µêµ¬ ìµœì €...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19618</th>\n",
       "      <td>clearance sale last day ê¸ˆì¼ ë°¤ 11ì‹œ 55ë¶„ í´ë¦¬ì–´ëŸ°ìŠ¤ ì„¸ì¼ì´...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19619</th>\n",
       "      <td>congratulation ì—¬ë¦„ì‹œì¦Œ 1ì°¨ë“œë¡­ ì´ë²¤íŠ¸ ë‹¹ì²¨ìë¥¼ ë°œí‘œí•©ë‹ˆë‹¤ ì˜¤ëŠ˜ ì˜¤ì „ì—...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18282 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        media_cn_cleaned  predicted_label\n",
       "0        yjm will drop a new album in the hottest summer               19\n",
       "1      ë§ˆì§€ë§‰ì— ë¬´ì„œìš´ ì‚¬ì§„ì´ ë‚˜ì˜µë‹ˆë‹¤ ì´íƒœë¦¬ ê³µí•­ì—ì„œ ë§ˆë¬´ë¦¬ ë„ë„ˆì¸  ê¹Œì§€ ë§›ìˆìœ¼ë©´ 0ì¹¼ë¡œ...               17\n",
       "2      ì•ˆë…•í•˜ì„¸ìš” ê° ë¯¸ì‚¬ ì…ë‹ˆë‹¤ ê°€ì„ì´ë„¤ìš” ì € ì˜ ìµì—ˆìŠµë‹ˆë‹¤ ë¹¨ë¦¬ ìˆ˜í™•í•´ ì£¼ì§€ ì•Šìœ¼ë©´ ì©...               19\n",
       "3      í‘¸ë“œíŠ¸ëŸ­ìœ¼ë¡œ ì˜¤ëŠ”ë° ì—¬ê¸° ìˆœëŒ€ ë„ˆë¬´ ë§›ìˆì–´ ì•¼ì±„ê°€ë“ ì—¬ê¸° ìˆœëŒ€ê°€ ì€ê·¼ ë§›ìˆì–´ì„œ ì¤‘ë…...               18\n",
       "4      ì œí’ˆí˜‘ì°¬ ë§¤ì¼ë§¤ì¼ ì •ì„±ìœ¼ë¡œ ì§ì ‘ ë§Œë“œëŠ” í‘ì„ìì¸ì ˆë¯¸ ì²­ë…„ë–¡ì§‘ ëª…ë¡€í—Œ ì‹œê·¸ë‹ˆì²˜ ì œí’ˆ ...               24\n",
       "...                                                  ...              ...\n",
       "19615            kiiikiii with ssgëœë”ìŠ¤ kiiikiii í‚¤í‚¤ sui ìˆ˜ì´               14\n",
       "19616  í˜‘ì°¬ ì¹¨êµ¬ ë°”ê¿¨ë”ë‹ˆ í˜¸í…”ê°™ëŒ€ìš” ì ê¹ ì‚¬ëŠ” êµ°ì¸ê´€ì‚¬ì´ì§€ë§Œ ê¹”ê¿ˆí•˜ê²Œ ì‚´êµ¬ì‹¶ì–´ ë‚˜ì¤‘ì— ì´...               25\n",
       "19617  ê³µêµ¬ì˜ˆê³  duriofficial ê³µêµ¬ ì•ˆí•˜ëŠ” ë¸Œëœë“œ ë‘ë¦¬ ì¼ˆë¦¬ë§˜ì´ ìµœì´ˆë¡œ ê³µêµ¬ ìµœì €...                9\n",
       "19618  clearance sale last day ê¸ˆì¼ ë°¤ 11ì‹œ 55ë¶„ í´ë¦¬ì–´ëŸ°ìŠ¤ ì„¸ì¼ì´...               23\n",
       "19619  congratulation ì—¬ë¦„ì‹œì¦Œ 1ì°¨ë“œë¡­ ì´ë²¤íŠ¸ ë‹¹ì²¨ìë¥¼ ë°œí‘œí•©ë‹ˆë‹¤ ì˜¤ëŠ˜ ì˜¤ì „ì—...                9\n",
       "\n",
       "[18282 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c5e8771",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    " 'IT': 0,\n",
    " 'ê²Œì„': 1,\n",
    " 'ê²°í˜¼/ì—°ì• ': 2,\n",
    " 'êµìœ¡': 3,\n",
    " 'ë‹¤ì´ì–´íŠ¸/ê±´ê°•ë³´ì¡°ì‹í’ˆ': 4,\n",
    " 'ë§Œí™”/ì• ë‹ˆ/íˆ°': 5,\n",
    " 'ë¬¸êµ¬/ì™„êµ¬': 6,\n",
    " 'ë¯¸ìˆ /ë””ìì¸': 7,\n",
    " 'ë°˜ë ¤ë™ë¬¼': 8,\n",
    " 'ë² ì´ë¹„/í‚¤ì¦ˆ': 9,\n",
    " 'ë·°í‹°': 10,\n",
    " 'ë¸Œëœë“œê³µì‹ê³„ì •': 11,\n",
    " 'ì‚¬ì§„/ì˜ìƒ': 12,\n",
    " 'ì…€ëŸ½': 13,\n",
    " 'ìŠ¤í¬ì¸ ': 14,\n",
    " 'ì‹œì‚¬': 15,\n",
    " 'ì—”í„°í…Œì¸ë¨¼íŠ¸': 16,\n",
    " 'ì—¬í–‰/ê´€ê´‘': 17,\n",
    " 'ìœ ëª…ì¥ì†Œ/í•«í”Œ': 18,\n",
    " 'ì¼ìƒ': 19,\n",
    " 'ìë™ì°¨/ëª¨ë¹Œë¦¬í‹°': 20,\n",
    " 'ì§¤/ë°ˆ': 21,\n",
    " 'ì·¨ë¯¸': 22,\n",
    " 'íŒ¨ì…˜': 23,\n",
    " 'í‘¸ë“œ': 24,\n",
    " 'í™ˆ/ë¦¬ë¹™': 25\n",
    "}\n",
    "\n",
    "inv_label_map = {v: k for k, v in label_map.items()}\n",
    "new['single_label'] = new['predicted_label'].map(inv_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af377df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new.to_excel(\"C:/Users/ehddl/Desktop/ì—…ë¬´/code/sns-categorizer/new_3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa39579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sns-categorizer-wO1G7-CE-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
